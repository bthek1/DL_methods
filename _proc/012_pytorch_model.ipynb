{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Pytorch Model\n",
    "output-file: pytorch_model.html\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "title: Pytorch Model\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4cd6d-fc7f-49f3-a05f-bdb05c7cc484",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7d475-07b4-433d-86e0-157a6dd5f534",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc286aa-e51b-4926-a8e1-080503f5f450",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6216, -0.1012, -1.1285], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c7a6c-6090-4cdd-b087-bcee92871c90",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "y.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1207cd1-ca24-42db-8550-b306c541e8d6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0056, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y*2\n",
    "z.retain_grad()\n",
    "z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc41fe6-26f4-4a91-9b00-3487c2277f36",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "z.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed34d73-2987-41a7-a942-11b73e1e7d6f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.6216, -0.1012, -1.1285], requires_grad=True),\n",
       " tensor([0.3784, 1.8988, 0.8715], grad_fn=<AddBackward0>),\n",
       " tensor(3.0056, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f40d09-8990-471c-b32d-98bc95c11368",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5045, 2.5318, 1.1620]), tensor([0.5045, 2.5318, 1.1620]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7fb67-bfa6-406b-a4a5-c6bc998df512",
   "metadata": {},
   "source": [
    "## For multiple z values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c54f1e-602a-4db1-8840-3ed69306abfb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72c452-58da-4756-9605-c3f9281f0ff3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12344f4-e96c-4653-b233-76c56108a0c5",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1730,  1.0904, -0.4991], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe3493-1bf8-43eb-a29f-634535a2eab7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "y.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154749c-3252-4950-bf6a-48e2aec0e1e4",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.4438, 19.1016,  4.5051], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y*2\n",
    "z.retain_grad()\n",
    "#z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb09133-5b8c-494b-950c-462c65fe1ab0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017317f4-f1ad-4a9a-a4dd-f90b3a8ea94a",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1730,  1.0904, -0.4991], requires_grad=True),\n",
       " tensor([2.1730, 3.0904, 1.5009], grad_fn=<AddBackward0>),\n",
       " tensor([ 9.4438, 19.1016,  4.5051], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0375126-4612-4870-8994-47d407648bbb",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([8.6920e-01, 1.2362e+01, 6.0034e-03]),\n",
       " tensor([8.6920e-01, 1.2362e+01, 6.0034e-03]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f00fe5-360c-4642-9da0-de46311b01d0",
   "metadata": {},
   "source": [
    "## Stopping gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ca074-f4bd-4f19-a58a-48071858cb0b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1730,  1.0904, -0.4991])\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(False)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ecb7b4-5f47-48d9-a8d5-c90fe043ec6e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1730,  1.0904, -0.4991])\n"
     ]
    }
   ],
   "source": [
    "y = x.detach()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542d517-189e-407f-9dcb-4b43121efe92",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1730,  1.0904, -0.4991])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7186d2-bb14-467d-8bff-67025feb076c",
   "metadata": {},
   "source": [
    "## Zeroing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef4aff-c9cc-4fc9-8d6f-60284dd66c45",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n",
      "tensor([12., 12., 12., 12.])\n",
      "tensor([15., 15., 15., 15.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model_output = (weights * 3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f6962-debd-49fb-886d-cf08ca716afd",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model_output = (weights * 3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ddede-e181-4300-ba2f-c729f6ff29b7",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ddf0a-c5a3-48af-9d68-388247c82df4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "weights = torch.ones(4, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abacda1-565c-4ed6-a4d7-3a89d2c2ee7e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbdevAuto                 0.0.119        /home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list| grep nbdevAuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba73df-a459-4a98-bb19-b1c502620041",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from nbdevAuto import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3cefb-7f42-4506-a95d-14d0edfe2f1c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"692pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 692.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 688,-112 688,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M96,-72C96,-72 12,-72 12,-72 6,-72 0,-66 0,-60 0,-60 0,-48 0,-48 0,-42 6,-36 12,-36 12,-36 96,-36 96,-36 102,-36 108,-42 108,-48 108,-48 108,-60 108,-60 108,-66 102,-72 96,-72\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-50.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">x</text>\n",
       "</g>\n",
       "<!-- a -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" cx=\"198\" cy=\"-54\" rx=\"54\" ry=\"54\"/>\n",
       "<text text-anchor=\"middle\" x=\"198\" y=\"-50.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">a(x)</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;a -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;a</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M108.28,-54C116.56,-54 125.18,-54 133.66,-54\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"143.89,-54 133.89,-58.5 138.89,-54 133.89,-54 133.89,-54 133.89,-54 138.89,-54 133.89,-49.5 143.89,-54 143.89,-54\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>y</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M384,-72C384,-72 300,-72 300,-72 294,-72 288,-66 288,-60 288,-60 288,-48 288,-48 288,-42 294,-36 300,-36 300,-36 384,-36 384,-36 390,-36 396,-42 396,-48 396,-48 396,-60 396,-60 396,-66 390,-72 384,-72\"/>\n",
       "<text text-anchor=\"middle\" x=\"342\" y=\"-50.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">y</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M252.28,-54C260.56,-54 269.18,-54 277.66,-54\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"287.89,-54 277.89,-58.5 282.89,-54 277.89,-54 277.89,-54 277.89,-54 282.89,-54 277.89,-49.5 287.89,-54 287.89,-54\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" cx=\"486\" cy=\"-54\" rx=\"54\" ry=\"54\"/>\n",
       "<text text-anchor=\"middle\" x=\"486\" y=\"-50.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">b(y)</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;b -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>y&#45;&gt;b</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M396.28,-54C404.56,-54 413.18,-54 421.66,-54\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"431.89,-54 421.89,-58.5 426.89,-54 421.89,-54 421.89,-54 421.89,-54 426.89,-54 421.89,-49.5 431.89,-54 431.89,-54\"/>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>z</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M672,-72C672,-72 588,-72 588,-72 582,-72 576,-66 576,-60 576,-60 576,-48 576,-48 576,-42 582,-36 588,-36 588,-36 672,-36 672,-36 678,-36 684,-42 684,-48 684,-48 684,-60 684,-60 684,-66 678,-72 672,-72\"/>\n",
       "<text text-anchor=\"middle\" x=\"630\" y=\"-50.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">z</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;z -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>b&#45;&gt;z</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M540.28,-54C548.56,-54 557.18,-54 565.66,-54\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"575.89,-54 565.89,-58.5 570.89,-54 565.89,-54 565.89,-54 565.89,-54 570.89,-54 565.89,-49.5 575.89,-54 575.89,-54\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<nbdevAuto.functions.graph>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = functions.graph()\n",
    "# Add nodes with different shapes and formatting\n",
    "dot.node('x', 'x')\n",
    "dot.node('a', 'a(x)', shape='circle')\n",
    "dot.node('y', 'y')\n",
    "dot.node('b', 'b(y)', shape='circle')\n",
    "dot.node('z', 'z')\n",
    "\n",
    "# Add edges with custom labels and formatting\n",
    "dot.edge('x', 'a')\n",
    "dot.edge('a', 'y')\n",
    "dot.edge('y', 'b')\n",
    "dot.edge('b', 'z')\n",
    "\n",
    "# Render the graph\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9bdae8-2c85-43c6-a6da-a16f0b17aaa1",
   "metadata": {},
   "source": [
    "**Chain rule**\n",
    "\n",
    "$\\dfrac{\\delta z}{\\delta x} =  \\dfrac{\\delta z}{\\delta y} \\cdot \\dfrac{\\delta y}{\\delta x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518552a-9fff-4138-ada4-2335f03dc195",
   "metadata": {},
   "source": [
    "## Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0ef52-3edd-44e4-889c-94826446e336",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"404pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 404.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 400,-112 400,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M96,-99C96,-99 12,-99 12,-99 6,-99 0,-93 0,-87 0,-87 0,-75 0,-75 0,-69 6,-63 12,-63 12,-63 96,-63 96,-63 102,-63 108,-69 108,-75 108,-75 108,-87 108,-87 108,-93 102,-99 96,-99\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-77.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">x</text>\n",
       "</g>\n",
       "<!-- * -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>*</title>\n",
       "<ellipse fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" cx=\"198\" cy=\"-54\" rx=\"54\" ry=\"54\"/>\n",
       "<text text-anchor=\"middle\" x=\"198\" y=\"-50.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">f=x*y</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;* -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;*</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M108.28,-70.87C116.97,-69.22 126.04,-67.49 134.92,-65.8\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"144.84,-63.92 135.85,-70.21 139.92,-64.85 135.01,-65.79 135.01,-65.79 135.01,-65.79 139.92,-64.85 134.17,-61.37 144.84,-63.92 144.84,-63.92\"/>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>z</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M384,-72C384,-72 300,-72 300,-72 294,-72 288,-66 288,-60 288,-60 288,-48 288,-48 288,-42 294,-36 300,-36 300,-36 384,-36 384,-36 390,-36 396,-42 396,-48 396,-48 396,-60 396,-60 396,-66 390,-72 384,-72\"/>\n",
       "<text text-anchor=\"middle\" x=\"342\" y=\"-50.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">z</text>\n",
       "</g>\n",
       "<!-- *&#45;&gt;z -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>*&#45;&gt;z</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M252.28,-54C260.56,-54 269.18,-54 277.66,-54\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"287.89,-54 277.89,-58.5 282.89,-54 277.89,-54 277.89,-54 277.89,-54 282.89,-54 277.89,-49.5 287.89,-54 287.89,-54\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>y</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M96,-45C96,-45 12,-45 12,-45 6,-45 0,-39 0,-33 0,-33 0,-21 0,-21 0,-15 6,-9 12,-9 12,-9 96,-9 96,-9 102,-9 108,-15 108,-21 108,-21 108,-33 108,-33 108,-39 102,-45 96,-45\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-23.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;* -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>y&#45;&gt;*</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M108.28,-37.13C116.97,-38.78 126.04,-40.51 134.92,-42.2\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"144.84,-44.08 134.17,-46.63 139.92,-43.15 135.01,-42.21 135.01,-42.21 135.01,-42.21 139.92,-43.15 135.85,-37.79 144.84,-44.08 144.84,-44.08\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<nbdevAuto.functions.graph>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = functions.graph()\n",
    "# Add nodes with different shapes and formatting\n",
    "dot.node('x', 'x')\n",
    "dot.node('*', 'f=x*y', shape='circle')\n",
    "dot.node('y', 'y')\n",
    "dot.node('z', 'z')\n",
    "\n",
    "# Add edges with custom labels and formatting\n",
    "dot.edge('x', '*')\n",
    "dot.edge('y', '*')\n",
    "dot.edge('*', 'z')\n",
    "\n",
    "# Render the graph\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a32a0-32b1-4e97-8893-791150e4e663",
   "metadata": {},
   "source": [
    "$\\dfrac{\\delta z}{\\delta x}  = \\dfrac{\\delta xy}{\\delta x} = y$ \n",
    "\n",
    "$\\dfrac{\\delta z}{\\delta y}  = \\dfrac{\\delta xy}{\\delta y} = y$ \n",
    "\n",
    "\n",
    "$\\dfrac{\\delta  \\ \\text{loss}}{\\delta x}  = \\dfrac{\\delta  \\ \\text{loss}}{\\delta z}  \\cdot \\dfrac{\\delta  z}{\\delta x}  $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecccc7-a082-4dc7-9953-de0679ca42af",
   "metadata": {},
   "source": [
    "1. Forward pass: Computer loss\n",
    "2. Compute local gradients\n",
    "3. Backward pass: Compute dLoss/dWeights using the Chain Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5a131-87c6-4cde-9390-1b59e318c3ad",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"716pt\" height=\"170pt\"\n",
       " viewBox=\"0.00 0.00 716.00 170.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 166)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-166 712,-166 712,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M96,-153C96,-153 12,-153 12,-153 6,-153 0,-147 0,-141 0,-141 0,-129 0,-129 0,-123 6,-117 12,-117 12,-117 96,-117 96,-117 102,-117 108,-123 108,-129 108,-129 108,-141 108,-141 108,-147 102,-153 96,-153\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-131.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">x</text>\n",
       "</g>\n",
       "<!-- * -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>*</title>\n",
       "<ellipse fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" cx=\"199\" cy=\"-108\" rx=\"54\" ry=\"54\"/>\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-111.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">*</text>\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-96.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">y1=w*y</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;* -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;*</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M108.25,-124.95C117.23,-123.25 126.62,-121.48 135.8,-119.74\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"145.66,-117.88 136.67,-124.16 140.75,-118.81 135.83,-119.74 135.83,-119.74 135.83,-119.74 140.75,-118.81 135,-115.32 145.66,-117.88 145.66,-117.88\"/>\n",
       "</g>\n",
       "<!-- w -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>w</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M96,-99C96,-99 12,-99 12,-99 6,-99 0,-93 0,-87 0,-87 0,-75 0,-75 0,-69 6,-63 12,-63 12,-63 96,-63 96,-63 102,-63 108,-69 108,-75 108,-75 108,-87 108,-87 108,-93 102,-99 96,-99\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-77.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">w</text>\n",
       "</g>\n",
       "<!-- w&#45;&gt;* -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>w&#45;&gt;*</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M108.25,-91.05C117.23,-92.75 126.62,-94.52 135.8,-96.26\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"145.66,-98.12 135,-100.68 140.75,-97.19 135.83,-96.26 135.83,-96.26 135.83,-96.26 140.75,-97.19 136.67,-91.84 145.66,-98.12 145.66,-98.12\"/>\n",
       "</g>\n",
       "<!-- &#45; -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>&#45;</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M400,-53C400,-53 316,-53 316,-53 310,-53 304,-47 304,-41 304,-41 304,-27 304,-27 304,-21 310,-15 316,-15 316,-15 400,-15 400,-15 406,-15 412,-21 412,-27 412,-27 412,-41 412,-41 412,-47 406,-53 400,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-37.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"358\" y=\"-22.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">s= y1&#45;y</text>\n",
       "</g>\n",
       "<!-- *&#45;&gt;&#45; -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>*&#45;&gt;&#45;</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M248.39,-85.19C267.04,-76.4 288.36,-66.35 307.15,-57.49\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"316.43,-53.12 309.31,-61.45 311.91,-55.25 307.39,-57.38 307.39,-57.38 307.39,-57.38 311.91,-55.25 305.47,-53.31 316.43,-53.12 316.43,-53.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.5\" y=\"-76.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\">y1</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M241,-36C241,-36 157,-36 157,-36 151,-36 145,-30 145,-24 145,-24 145,-12 145,-12 145,-6 151,0 157,0 157,0 241,0 241,0 247,0 253,-6 253,-12 253,-12 253,-24 253,-24 253,-30 247,-36 241,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"199\" y=\"-14.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">y</text>\n",
       "</g>\n",
       "<!-- y&#45;&gt;&#45; -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>y&#45;&gt;&#45;</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M253.15,-23.42C266.2,-24.75 280.29,-26.18 293.75,-27.55\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"303.9,-28.59 293.5,-32.05 298.93,-28.08 293.95,-27.57 293.95,-27.57 293.95,-27.57 298.93,-28.08 294.41,-23.1 303.9,-28.59 303.9,-28.59\"/>\n",
       "</g>\n",
       "<!-- ^2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>^2</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M551,-53C551,-53 467,-53 467,-53 461,-53 455,-47 455,-41 455,-41 455,-27 455,-27 455,-21 461,-15 467,-15 467,-15 551,-15 551,-15 557,-15 563,-21 563,-27 563,-27 563,-41 563,-41 563,-47 557,-53 551,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"509\" y=\"-37.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">^2</text>\n",
       "<text text-anchor=\"middle\" x=\"509\" y=\"-22.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">(y1&#45;y)^2</text>\n",
       "</g>\n",
       "<!-- &#45;&#45;&gt;^2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>&#45;&#45;&gt;^2</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M412.37,-34C422.81,-34 433.86,-34 444.59,-34\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"454.75,-34 444.75,-38.5 449.75,-34 444.75,-34 444.75,-34 444.75,-34 449.75,-34 444.75,-29.5 454.75,-34 454.75,-34\"/>\n",
       "<text text-anchor=\"middle\" x=\"433.5\" y=\"-37.8\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\">s</text>\n",
       "</g>\n",
       "<!-- Loss -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Loss</title>\n",
       "<path fill=\"#fcbf49\" stroke=\"black\" stroke-width=\"0\" d=\"M696,-52C696,-52 612,-52 612,-52 606,-52 600,-46 600,-40 600,-40 600,-28 600,-28 600,-22 606,-16 612,-16 612,-16 696,-16 696,-16 702,-16 708,-22 708,-28 708,-28 708,-40 708,-40 708,-46 702,-52 696,-52\"/>\n",
       "<text text-anchor=\"middle\" x=\"654\" y=\"-30.3\" font-family=\"Helvetica,Arial,sans-serif\" font-size=\"14.00\" fill=\"#003049\">Loss</text>\n",
       "</g>\n",
       "<!-- ^2&#45;&gt;Loss -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>^2&#45;&gt;Loss</title>\n",
       "<path fill=\"none\" stroke=\"#003049\" d=\"M563.25,-34C571.81,-34 580.74,-34 589.52,-34\"/>\n",
       "<polygon fill=\"#003049\" stroke=\"#003049\" points=\"599.71,-34 589.71,-38.5 594.71,-34 589.71,-34 589.71,-34 589.71,-34 594.71,-34 589.71,-29.5 599.71,-34 599.71,-34\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<nbdevAuto.functions.graph>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = functions.graph()\n",
    "# Add nodes with different shapes and formatting\n",
    "dot.node('x', 'x')\n",
    "dot.node('w', 'w')\n",
    "dot.node('*', '*\\ny1=w*y', shape='circle')\n",
    "\n",
    "dot.node('y', 'y')\n",
    "dot.node('-', '-\\ns= y1-y')\n",
    "\n",
    "dot.node('^2', '^2\\n(y1-y)^2')\n",
    "dot.node('Loss', 'Loss')\n",
    "# Add edges with custom labels and formatting\n",
    "dot.edge('x', '*')\n",
    "dot.edge('w', '*')\n",
    "\n",
    "dot.edge('*', '-', label='y1')\n",
    "dot.edge('y', '-')\n",
    "\n",
    "dot.edge('-', '^2', label='s')\n",
    "\n",
    "dot.edge('^2', 'Loss')\n",
    "# Render the graph\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b34fab-a1dd-4112-a01a-115e6cbeae66",
   "metadata": {},
   "source": [
    "$Loss = (\\hat{y} - y)^2$ \n",
    "\n",
    "$\\dfrac{\\delta loss}{\\delta s} = \\dfrac{s^2}{s} = 2s$\n",
    "\n",
    "$\\dfrac{\\delta s}{\\delta \\hat{y}} = \\dfrac{\\delta\\hat{y} - y}{\\delta \\hat{y}} = 1$\n",
    "\n",
    "$\\dfrac{\\delta \\hat{y}}{\\delta w} = \\dfrac{\\delta wx}{\\delta w} = x$\n",
    "\n",
    "$\\therefore \\dfrac{\\delta loss}{\\delta w} = \\dfrac{\\delta loss}{\\delta s} \\cdot \\dfrac{\\delta s}{\\delta y} \\cdot  \\dfrac{\\delta \\hat{y}}{\\delta w} = 2 \\cdot s \\cdot x = 2 \\cdot (-1) \\cdot (1) = -2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c03b0-ec4c-4b0b-bbc8-b480b6d74923",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = 1\n",
    "y = 2\n",
    "w = 1\n",
    "\n",
    "y1 = x * w \n",
    "s = y1-y\n",
    "loss = s**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c61826-d525-41fa-8a8e-7ce210681775",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:1 w:1 y1:1 y:2 s:-1 loss:1\n"
     ]
    }
   ],
   "source": [
    "print(f'x:{x} w:{w} y1:{y1} y:{y} s:{s} loss:{loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2c98f-bf52-48a5-93a4-5fe7a7368b9a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014fb42-1132-45ac-894b-c476e498a8b2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad = True)\n",
    "\n",
    "lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56837c07-95f9-4594-b2cd-9cc794e5cbfd",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<MulBackward0>)\n",
      "tensor(1., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#forward pass and compute the loss\n",
    "y1 = w * x\n",
    "loss = (y1-y)**2\n",
    "\n",
    "print(y1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50faa847-b270-4e92-98f4-3029d4f33458",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "w.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0dc0df-fda4-4ee0-99c6-b382e6b530cf",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82af36-03e3-4bb0-9f3d-b2fe68827ed9",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "\n",
    "> Prediction: Manually\n",
    "\n",
    "> Gradients Computation: Manually\n",
    "\n",
    "> Loss Computation: Manually\n",
    "\n",
    "> Parameter updates: Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdba60-4289-4451-be1c-21f83694efa4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179fc8e-0031-45e4-a426-337ca956b92f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4], dtype=np.float32)\n",
    "y = np.array([2,4,6,8], dtype=np.float32)\n",
    "\n",
    "w = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606f231-fccf-4706-823e-5d3d0f63cc7b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9bf59-0c7e-46ee-8723-8832d80dfdb9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n"
     ]
    }
   ],
   "source": [
    "# gradient\n",
    "\n",
    "# MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N 2x (w*x - y)\n",
    "\n",
    "def gradient (x, y, y_predicted):\n",
    "    return np.dot(2 * x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014d106-06fd-4a65-a0c3-b150ff372d91",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc:0  w = 1.200 , y_pred=6.0, y = 10, loss = 30.00000000, dw = -120.0\n",
      "epoc:1  w = 1.680 , y_pred=8.399999809265136, y = 10, loss = 4.79999924, dw = -47.999996185302734\n",
      "epoc:2  w = 1.872 , y_pred=9.35999994277954, y = 10, loss = 0.76800019, dw = -19.200002670288086\n",
      "epoc:3  w = 1.949 , y_pred=9.743999934196472, y = 10, loss = 0.12288000, dw = -7.679999828338623\n",
      "epoc:4  w = 1.980 , y_pred=9.897600066661834, y = 10, loss = 0.01966083, dw = -3.072002649307251\n",
      "epoc:5  w = 1.992 , y_pred=9.95904014110565, y = 10, loss = 0.00314574, dw = -1.2288014888763428\n",
      "epoc:6  w = 1.997 , y_pred=9.983615934848784, y = 10, loss = 0.00050331, dw = -0.4915158748626709\n",
      "epoc:7  w = 1.999 , y_pred=9.993446409702301, y = 10, loss = 0.00008053, dw = -0.1966094970703125\n",
      "epoc:8  w = 1.999 , y_pred=9.997378492355345, y = 10, loss = 0.00001288, dw = -0.07864165306091309\n",
      "epoc:9  w = 2.000 , y_pred=9.998951268196105, y = 10, loss = 0.00000206, dw = -0.03145551681518555\n",
      "epoc:10  w = 2.000 , y_pred=9.999580299854276, y = 10, loss = 0.00000033, dw = -0.012580633163452148\n",
      "epoc:11  w = 2.000 , y_pred=9.999832069873808, y = 10, loss = 0.00000005, dw = -0.005035400390625\n",
      "epoc:12  w = 2.000 , y_pred=9.999932992458342, y = 10, loss = 0.00000001, dw = -0.002018451690673828\n",
      "epoc:13  w = 2.000 , y_pred=9.999973046779632, y = 10, loss = 0.00000000, dw = -0.00080108642578125\n",
      "epoc:14  w = 2.000 , y_pred=9.999989175796507, y = 10, loss = 0.00000000, dw = -0.00032258033752441406\n",
      "Prediction after training: 10.000, y = 10\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 15\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(x)\n",
    "\n",
    "    # loss \n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradients\n",
    "    dw = gradient(x, y, y_pred)\n",
    "\n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoc:{epoch}  w = {w:.3f} , y_pred={forward(5)}, y = {10}, loss = {l:.8f}, dw = {dw}')\n",
    "\n",
    "print(f'Prediction after training: {forward(5):.3f}, y = {10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab47a35-1fce-4aba-8ee1-1f6ccdc5708e",
   "metadata": {},
   "source": [
    "### Torch\n",
    "\n",
    "\n",
    "> Prediction: Manually\n",
    "\n",
    "> Gradients Computation: Autograd\n",
    "\n",
    "> Loss Computation: Manually\n",
    "\n",
    "> Parameter updates: Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59981f51-02ed-4521-94df-0061de0bd327",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor([0.0], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da2246-2da0-46c4-8440-76c672faa86f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061265cd-72fe-4e64-ac31-d0b671971a16",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = tensor([0.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# gradient\n",
    "\n",
    "# MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N 2x (w*x - y)\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2daa0-dad6-4f69-ae67-ba6847c7221f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc:0  w = 0.300, y_pred=1.500, y = 10, loss = 30.0000000, dw = -30.0000000\n",
      "epoc:2  w = 0.772, y_pred=3.859, y = 10, loss = 15.6601877, dw = -21.6749992\n",
      "epoc:4  w = 1.113, y_pred=5.563, y = 10, loss = 8.1747169, dw = -15.6601877\n",
      "epoc:6  w = 1.359, y_pred=6.794, y = 10, loss = 4.2672529, dw = -11.3144855\n",
      "epoc:8  w = 1.537, y_pred=7.684, y = 10, loss = 2.2275321, dw = -8.1747150\n",
      "epoc:10  w = 1.665, y_pred=8.327, y = 10, loss = 1.1627856, dw = -5.9062314\n",
      "epoc:12  w = 1.758, y_pred=8.791, y = 10, loss = 0.6069812, dw = -4.2672515\n",
      "epoc:14  w = 1.825, y_pred=9.126, y = 10, loss = 0.3168478, dw = -3.0830884\n",
      "epoc:16  w = 1.874, y_pred=9.369, y = 10, loss = 0.1653965, dw = -2.2275314\n",
      "epoc:18  w = 1.909, y_pred=9.544, y = 10, loss = 0.0863381, dw = -1.6093917\n",
      "epoc:20  w = 1.934, y_pred=9.671, y = 10, loss = 0.0450689, dw = -1.1627841\n",
      "epoc:22  w = 1.952, y_pred=9.762, y = 10, loss = 0.0235263, dw = -0.8401127\n",
      "epoc:24  w = 1.966, y_pred=9.828, y = 10, loss = 0.0122808, dw = -0.6069803\n",
      "epoc:26  w = 1.975, y_pred=9.876, y = 10, loss = 0.0064107, dw = -0.4385428\n",
      "epoc:28  w = 1.982, y_pred=9.910, y = 10, loss = 0.0033464, dw = -0.3168479\n",
      "epoc:30  w = 1.987, y_pred=9.935, y = 10, loss = 0.0017469, dw = -0.2289228\n",
      "epoc:32  w = 1.991, y_pred=9.953, y = 10, loss = 0.0009119, dw = -0.1653977\n",
      "epoc:34  w = 1.993, y_pred=9.966, y = 10, loss = 0.0004760, dw = -0.1194997\n",
      "epoc:36  w = 1.995, y_pred=9.976, y = 10, loss = 0.0002485, dw = -0.0863385\n",
      "epoc:38  w = 1.996, y_pred=9.982, y = 10, loss = 0.0001297, dw = -0.0623794\n",
      "epoc:40  w = 1.997, y_pred=9.987, y = 10, loss = 0.0000677, dw = -0.0450683\n",
      "epoc:42  w = 1.998, y_pred=9.991, y = 10, loss = 0.0000353, dw = -0.0325624\n",
      "epoc:44  w = 1.999, y_pred=9.993, y = 10, loss = 0.0000184, dw = -0.0235248\n",
      "epoc:46  w = 1.999, y_pred=9.995, y = 10, loss = 0.0000096, dw = -0.0169984\n",
      "epoc:48  w = 1.999, y_pred=9.997, y = 10, loss = 0.0000050, dw = -0.0122809\n",
      "Prediction after training: tensor([9.9970], grad_fn=<MulBackward0>), y = 10\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 50\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(x)\n",
    "\n",
    "    # loss \n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradients\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoc:{epoch}  w = {w.item():.3f}, y_pred={forward(5).item():.3f}, y = {10}, loss = {l.item():.7f}, dw = {w.grad.item():.7f}')\n",
    "\n",
    "    w.grad.zero_()\n",
    "\n",
    "print(f'Prediction after training: {forward(5)}, y = {10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f3f58-8b23-4542-a54f-9e6a7f1e0907",
   "metadata": {},
   "source": [
    "### Pytorch Loss and Pytorch Optimizer\n",
    "\n",
    "\n",
    "> Prediction: Manually\n",
    "\n",
    "> Gradients Computation: Autograd\n",
    "\n",
    "> Loss Computation: Pytorch Loss\n",
    "\n",
    "> Parameter updates: Pytorch Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ecce1-6a61-4719-b7a1-72ab528819ec",
   "metadata": {},
   "source": [
    "1. Design Model = (input, output, size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a6098-7ef0-4dc2-a731-d75035026327",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor([0.0], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d25965-c68f-4904-b336-864b82441001",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "def forward(x):\n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c03c49-f473-4d96-b2bd-3e9d0675e13d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = tensor([0.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f(5) = {forward(5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1404c5a-6174-4ff0-b906-9e87e7d1b8be",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc:0  w = 0.300, y_pred=1.500, y = 10, loss = 30.0000000, dw = -30.0000000\n",
      "epoc:2  w = 0.772, y_pred=3.859, y = 10, loss = 15.6601877, dw = -21.6749992\n",
      "epoc:4  w = 1.113, y_pred=5.563, y = 10, loss = 8.1747169, dw = -15.6601877\n",
      "epoc:6  w = 1.359, y_pred=6.794, y = 10, loss = 4.2672529, dw = -11.3144855\n",
      "epoc:8  w = 1.537, y_pred=7.684, y = 10, loss = 2.2275321, dw = -8.1747150\n",
      "epoc:10  w = 1.665, y_pred=8.327, y = 10, loss = 1.1627856, dw = -5.9062314\n",
      "epoc:12  w = 1.758, y_pred=8.791, y = 10, loss = 0.6069812, dw = -4.2672515\n",
      "epoc:14  w = 1.825, y_pred=9.126, y = 10, loss = 0.3168478, dw = -3.0830884\n",
      "epoc:16  w = 1.874, y_pred=9.369, y = 10, loss = 0.1653965, dw = -2.2275314\n",
      "epoc:18  w = 1.909, y_pred=9.544, y = 10, loss = 0.0863381, dw = -1.6093917\n",
      "epoc:20  w = 1.934, y_pred=9.671, y = 10, loss = 0.0450689, dw = -1.1627841\n",
      "epoc:22  w = 1.952, y_pred=9.762, y = 10, loss = 0.0235263, dw = -0.8401127\n",
      "epoc:24  w = 1.966, y_pred=9.828, y = 10, loss = 0.0122808, dw = -0.6069803\n",
      "epoc:26  w = 1.975, y_pred=9.876, y = 10, loss = 0.0064107, dw = -0.4385428\n",
      "epoc:28  w = 1.982, y_pred=9.910, y = 10, loss = 0.0033464, dw = -0.3168479\n",
      "epoc:30  w = 1.987, y_pred=9.935, y = 10, loss = 0.0017469, dw = -0.2289228\n",
      "epoc:32  w = 1.991, y_pred=9.953, y = 10, loss = 0.0009119, dw = -0.1653977\n",
      "epoc:34  w = 1.993, y_pred=9.966, y = 10, loss = 0.0004760, dw = -0.1194997\n",
      "epoc:36  w = 1.995, y_pred=9.976, y = 10, loss = 0.0002485, dw = -0.0863385\n",
      "epoc:38  w = 1.996, y_pred=9.982, y = 10, loss = 0.0001297, dw = -0.0623794\n",
      "epoc:40  w = 1.997, y_pred=9.987, y = 10, loss = 0.0000677, dw = -0.0450683\n",
      "epoc:42  w = 1.998, y_pred=9.991, y = 10, loss = 0.0000353, dw = -0.0325624\n",
      "epoc:44  w = 1.999, y_pred=9.993, y = 10, loss = 0.0000184, dw = -0.0235248\n",
      "epoc:46  w = 1.999, y_pred=9.995, y = 10, loss = 0.0000096, dw = -0.0169984\n",
      "epoc:48  w = 1.999, y_pred=9.997, y = 10, loss = 0.0000050, dw = -0.0122809\n",
      "Prediction after training: tensor([9.9970], grad_fn=<MulBackward0>), y = 10\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 50\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr= learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(x)\n",
    "\n",
    "    # loss \n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradients\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoc:{epoch}  w = {w.item():.3f}, y_pred={forward(5).item():.3f}, y = {10}, loss = {l.item():.7f}, dw = {w.grad.item():.7f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(f'Prediction after training: {forward(5)}, y = {10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2839fd-2705-4198-964b-df199929895b",
   "metadata": {},
   "source": [
    "### Pytorch Automate\n",
    "\n",
    "\n",
    "> Prediction: Manually\n",
    "\n",
    "> Gradients Computation: Autograd\n",
    "\n",
    "> Loss Computation: Pytorch Loss\n",
    "\n",
    "> Parameter updates: Pytorch Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04319a-ca64-4905-bef8-7728fef9910a",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "\n",
    "x_test = torch.tensor([5], dtype = torch.float32)\n",
    "n_samples, n_features = x.shape\n",
    "n_samples, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57b743-dc1c-47a0-8f31-0e6c190a2027",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(in_features = n_features, out_features = 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59afc7-d5bf-47ea-8892-b9115cdd6f64",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9119284152984619"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w,b] = model.parameters()\n",
    "w[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f233e0e-4437-4c25-89de-2ef25d870f30",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9119]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfa11a-13f1-49b9-9566-74d4ec088e6e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = tensor([-4.1126], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f(5) = {model(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254cad50-7d4a-4b82-b8b5-d1bb9f1c3eaf",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc:0  w = 3.232 1.814, y_pred=17.976, y = 10, loss = 57.2857742, dw = -41.4436264\n",
      "epoc:20  w = 1.769 0.681, y_pred=9.526, y = 10, loss = 0.0821977, dw = -0.0851871\n",
      "epoc:40  w = 1.874 0.371, y_pred=9.740, y = 10, loss = 0.0243662, dw = -0.0389004\n",
      "epoc:60  w = 1.931 0.202, y_pred=9.859, y = 10, loss = 0.0072235, dw = -0.0211780\n",
      "epoc:80  w = 1.963 0.110, y_pred=9.923, y = 10, loss = 0.0021415, dw = -0.0115299\n",
      "epoc:100  w = 1.980 0.060, y_pred=9.958, y = 10, loss = 0.0006349, dw = -0.0062776\n",
      "epoc:120  w = 1.989 0.033, y_pred=9.977, y = 10, loss = 0.0001882, dw = -0.0034181\n",
      "epoc:140  w = 1.994 0.018, y_pred=9.988, y = 10, loss = 0.0000558, dw = -0.0018613\n",
      "epoc:160  w = 1.997 0.010, y_pred=9.993, y = 10, loss = 0.0000165, dw = -0.0010126\n",
      "epoc:180  w = 1.998 0.005, y_pred=9.996, y = 10, loss = 0.0000049, dw = -0.0005509\n",
      "epoc:200  w = 1.999 0.003, y_pred=9.998, y = 10, loss = 0.0000015, dw = -0.0003018\n",
      "epoc:220  w = 1.999 0.002, y_pred=9.999, y = 10, loss = 0.0000004, dw = -0.0001646\n",
      "epoc:240  w = 2.000 0.001, y_pred=9.999, y = 10, loss = 0.0000001, dw = -0.0000905\n",
      "epoc:260  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000502\n",
      "epoc:280  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000285\n",
      "epoc:300  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000144\n",
      "epoc:320  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000073\n",
      "epoc:340  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000048\n",
      "epoc:360  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000023\n",
      "epoc:380  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000024\n",
      "epoc:400  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000024\n",
      "epoc:420  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = 0.0000007\n",
      "epoc:440  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000008\n",
      "epoc:460  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = 0.0000010\n",
      "epoc:480  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000014\n",
      "Prediction after training: tensor([10.0000], grad_fn=<ViewBackward0>), y = 10\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "n_iters = 500\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # loss \n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradients\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoc:{epoch}  w = {w[0].item():.3f} {b[0].item():.3f}, y_pred={model(x_test).item():.3f}, y = {10}, loss = {l.item():.7f}, dw = {w.grad.item():.7f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(f'Prediction after training: {model(x_test)}, y = {10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b8a74-5942-4914-acfa-cd385e32ded4",
   "metadata": {},
   "source": [
    "### Pytorch Model\n",
    "\n",
    "\n",
    "> Prediction: Manually\n",
    "\n",
    "> Gradients Computation: Autograd\n",
    "\n",
    "> Loss Computation: Pytorch Loss\n",
    "\n",
    "> Parameter updates: Pytorch Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3713518-392a-4b73-80ca-294ddfd6d91b",
   "metadata": {},
   "source": [
    "1. Design Model = (input, output, size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "   - forward pass: compute prediction\n",
    "   - backward pass: gradients\n",
    "   - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e479159d-3d24-414f-8b9d-8bdfd2b1377b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "\n",
    "x_test = torch.tensor([5], dtype = torch.float32)\n",
    "n_samples, n_features = x.shape\n",
    "n_samples, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ba483-2e5f-4f98-b92e-19915f247607",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(in_features = n_features, out_features = 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627e323-4817-4b0f-8f1b-d6e78421b47e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "  (lin): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LinearRegression, self).__init__()\n",
    "\n",
    "        self.lin = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(in_features = n_features, out_features = 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1802bf1-28fc-41ed-b7e1-e371d03622ba",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014849305152893066"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w,b] = model.parameters()\n",
    "w[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24fbb0-ab14-40ad-afd7-28b581a6a89f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0148]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['lin.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9568e34a-19fe-4eb1-949f-75d8ba8a5dc4",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = tensor([0.8469], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f(5) = {model(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1485ec-5376-4d13-abcf-8ab5a60f9ec3",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc:0  w = 2.606 1.611, y_pred=14.642, y = 10, loss = 22.4837551, dw = -25.9138470\n",
      "epoc:20  w = 1.767 0.686, y_pred=9.522, y = 10, loss = 0.0833880, dw = -0.0805315\n",
      "epoc:40  w = 1.873 0.373, y_pred=9.739, y = 10, loss = 0.0247202, dw = -0.0391794\n",
      "epoc:60  w = 1.931 0.203, y_pred=9.858, y = 10, loss = 0.0073285, dw = -0.0213290\n",
      "epoc:80  w = 1.962 0.111, y_pred=9.922, y = 10, loss = 0.0021726, dw = -0.0116135\n",
      "epoc:100  w = 1.980 0.060, y_pred=9.958, y = 10, loss = 0.0006441, dw = -0.0063227\n",
      "epoc:120  w = 1.989 0.033, y_pred=9.977, y = 10, loss = 0.0001909, dw = -0.0034429\n",
      "epoc:140  w = 1.994 0.018, y_pred=9.987, y = 10, loss = 0.0000566, dw = -0.0018725\n",
      "epoc:160  w = 1.997 0.010, y_pred=9.993, y = 10, loss = 0.0000168, dw = -0.0010188\n",
      "epoc:180  w = 1.998 0.005, y_pred=9.996, y = 10, loss = 0.0000050, dw = -0.0005555\n",
      "epoc:200  w = 1.999 0.003, y_pred=9.998, y = 10, loss = 0.0000015, dw = -0.0003012\n",
      "epoc:220  w = 1.999 0.002, y_pred=9.999, y = 10, loss = 0.0000004, dw = -0.0001644\n",
      "epoc:240  w = 2.000 0.001, y_pred=9.999, y = 10, loss = 0.0000001, dw = -0.0000920\n",
      "epoc:260  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000499\n",
      "epoc:280  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000279\n",
      "epoc:300  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000136\n",
      "epoc:320  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000103\n",
      "epoc:340  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000025\n",
      "epoc:360  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000039\n",
      "epoc:380  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000024\n",
      "epoc:400  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000023\n",
      "epoc:420  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000007\n",
      "epoc:440  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = -0.0000008\n",
      "epoc:460  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = 0.0000010\n",
      "epoc:480  w = 2.000 0.000, y_pred=10.000, y = 10, loss = 0.0000000, dw = 0.0000007\n",
      "Prediction after training: tensor([10.], grad_fn=<ViewBackward0>), y = 10\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "n_iters = 500\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # loss \n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradients\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoc:{epoch}  w = {w[0].item():.3f} {b[0].item():.3f}, y_pred={model(x_test).item():.3f}, y = {10}, loss = {l.item():.7f}, dw = {w.grad.item():.7f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(f'Prediction after training: {model(x_test)}, y = {10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586377df-a03f-47fb-85c7-3e91dc45adf4",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e8261-ad20-4600-8736-7b9150b74ea5",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3501e26-9396-4cfc-9ef3-aeea1f1cb9b9",
   "metadata": {},
   "source": [
    "1. Prepare data\n",
    "2. model\n",
    "3. loss and optimizer\n",
    "4. training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbfc4ab-3b47-406f-9414-4abcbe929cfc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x_numpy, y_numpy = datasets.make_regression(n_samples= 100, n_features=1, noise = 20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539b597-7e53-4511-bfc5-2817adc6bd57",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.6118],\n",
       "         [-0.2494],\n",
       "         [ 0.4885],\n",
       "         [ 0.7620],\n",
       "         [ 1.5198]]),\n",
       " tensor([-55.5386, -10.6620,  22.7574, 101.0961, 144.3376]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(x_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3ec4c-4535-4f7f-aab4-47cb3ab8cd4d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.5198]), tensor(144.3376))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x[4]\n",
    "y_test = y[4]\n",
    "x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ee7f7-afd4-4896-849e-4f5a9ee80d39",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.6118],\n",
       "         [-0.2494],\n",
       "         [ 0.4885],\n",
       "         [ 0.7620],\n",
       "         [ 1.5198]]),\n",
       " tensor([[-55.5386],\n",
       "         [-10.6620],\n",
       "         [ 22.7574],\n",
       "         [101.0961],\n",
       "         [144.3376]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =y.view(y.shape[0], 1)\n",
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a2134-62b2-4b2c-b8d8-5875569281bf",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, n_features = x.shape\n",
    "n_samples, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3027f4-e24a-418d-b24d-a09876744bd5",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a87ba-78c1-4d1e-a205-2395a4a0269c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.4086]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.7387], requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a,b] = model.parameters()\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc1032-8664-4ec7-b21a-44a689d26ad9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#2. loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b4773-a627-4c74-858d-bf8d31b1c1e2",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd6f43-1a11-47ed-99c4-de05e05fec63",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoc:49] (y = 74.751x + 4.940) y_pred:118.547, y:144.33755493164062, loss :381.1035156, dw:-12.2604523 db:0.8364363\n",
      "[epoc:99] (y = 78.958x + 4.571) y_pred:124.573, y:144.33755493164062, loss :342.7143860, dw:-5.5758629 db:0.6129383\n",
      "[epoc:149] (y = 80.874x + 4.331) y_pred:127.245, y:144.33755493164062, loss :334.6977844, dw:-2.5416768 db:0.3636089\n",
      "[epoc:199] (y = 81.748x + 4.196) y_pred:128.437, y:144.33755493164062, loss :333.0159302, dw:-1.1606977 db:0.1964752\n",
      "[epoc:249] (y = 82.147x + 4.124) y_pred:128.973, y:144.33755493164062, loss :332.6621094, dw:-0.5308060 db:0.1008240\n",
      "[epoc:299] (y = 82.330x + 4.088) y_pred:129.214, y:144.33755493164062, loss :332.5874939, dw:-0.2430411 db:0.0501155\n",
      "[epoc:349] (y = 82.414x + 4.070) y_pred:129.324, y:144.33755493164062, loss :332.5718079, dw:-0.1113836 db:0.0243861\n",
      "[epoc:399] (y = 82.452x + 4.062) y_pred:129.374, y:144.33755493164062, loss :332.5684509, dw:-0.0510854 db:0.0116911\n",
      "[epoc:449] (y = 82.470x + 4.058) y_pred:129.396, y:144.33755493164062, loss :332.5677490, dw:-0.0234327 db:0.0055519\n",
      "[epoc:499] (y = 82.478x + 4.056) y_pred:129.407, y:144.33755493164062, loss :332.5676270, dw:-0.0107710 db:0.0026089\n",
      "[epoc:549] (y = 82.481x + 4.055) y_pred:129.411, y:144.33755493164062, loss :332.5675354, dw:-0.0049383 db:0.0012246\n",
      "[epoc:599] (y = 82.483x + 4.054) y_pred:129.414, y:144.33755493164062, loss :332.5675354, dw:-0.0022874 db:0.0005701\n",
      "[epoc:649] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675354, dw:-0.0010635 db:0.0002615\n",
      "[epoc:699] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675354, dw:-0.0004754 db:0.0001256\n",
      "[epoc:749] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675659, dw:-0.0003702 db:0.0000544\n",
      "[epoc:799] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675659, dw:-0.0003721 db:0.0000235\n",
      "[epoc:849] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675659, dw:-0.0003721 db:0.0000235\n",
      "[epoc:899] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675659, dw:-0.0003721 db:0.0000235\n",
      "[epoc:949] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675659, dw:-0.0003721 db:0.0000235\n",
      "[epoc:999] (y = 82.484x + 4.054) y_pred:129.415, y:144.33755493164062, loss :332.5675659, dw:-0.0003721 db:0.0000235\n"
     ]
    }
   ],
   "source": [
    "#3. training loop\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_predicted = model(x)\n",
    "    loss=criterion(y_predicted, y)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'[epoc:{epoch}] (y = {w[0].item():.3f}x + {b[0].item():.3f}) y_pred:{model(x_test).item():.3f}, y:{y_test}, loss :{loss.item():.7f}, dw:{w.grad.item():.7f} db:{b.grad.item():.7f}')\n",
    "\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b73a0-5c59-4b36-9c56-2b34fb739266",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "predicted = model(x).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73588ba5-bc7e-4c12-b050-659824605e3f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_numpy, y_numpy, 'ro')\n",
    "plt.plot(x_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3dfa35-a871-4860-8fce-c4a05624a537",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927b73f-0f37-4491-a032-762c69749d22",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e30e6778-14d4-4290-8799-2f3df91091f5\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "'use strict';\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded(error = null) {\n",
       "    const el = document.getElementById(\"e30e6778-14d4-4290-8799-2f3df91091f5\");\n",
       "    if (el != null) {\n",
       "      const html = (() => {\n",
       "        if (typeof root.Bokeh === \"undefined\") {\n",
       "          if (error == null) {\n",
       "            return \"BokehJS is loading ...\";\n",
       "          } else {\n",
       "            return \"BokehJS failed to load.\";\n",
       "          }\n",
       "        } else {\n",
       "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
       "          if (error == null) {\n",
       "            return `${prefix} successfully loaded.`;\n",
       "          } else {\n",
       "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
       "          }\n",
       "        }\n",
       "      })();\n",
       "      el.innerHTML = html;\n",
       "\n",
       "      if (error != null) {\n",
       "        const wrapper = document.createElement(\"div\");\n",
       "        wrapper.style.overflow = \"auto\";\n",
       "        wrapper.style.height = \"5em\";\n",
       "        wrapper.style.resize = \"vertical\";\n",
       "        const content = document.createElement(\"div\");\n",
       "        content.style.fontFamily = \"monospace\";\n",
       "        content.style.whiteSpace = \"pre-wrap\";\n",
       "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
       "        content.textContent = error.stack ?? error.toString();\n",
       "        wrapper.append(content);\n",
       "        el.append(wrapper);\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(() => display_loaded(error), 100);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      try {\n",
       "            for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "\n",
       "      } catch (error) {display_loaded(error);throw error;\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"e30e6778-14d4-4290-8799-2f3df91091f5\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"e30e6778-14d4-4290-8799-2f3df91091f5\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e30e6778-14d4-4290-8799-2f3df91091f5\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606dc695-2ea7-4b1a-bc3e-f9ecf4db85fe",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"b436194f-d535-46f5-8f7a-6821750d91d7\" data-root-id=\"p2023\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"7c49a87b-b9d7-4ced-a909-87ed2d87a87c\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p2023\",\"attributes\":{\"height\":500,\"max_width\":1000,\"sizing_mode\":\"stretch_width\",\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p2024\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p2025\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p2033\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p2034\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p2026\",\"attributes\":{\"text\":\"Real data vs Model\",\"text_color\":\"#E0E0E0\",\"text_font\":\"Helvetica\",\"text_font_size\":\"1.15em\"}},\"outline_line_color\":\"#E0E0E0\",\"outline_line_alpha\":0.25,\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2062\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p2056\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p2057\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p2058\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"rdm3L4KT47/GI6JTXuvPv7RjuJ3hQ98/VQxURWVi6D9cGydwK1H4P/m+mUwBKtg/ANV6zOtp4D9zV3Aq2Xrlv4B8nooMWPa//ib461wz1D9AtraxRGLkvzfSmudoZNm/xq232iKc8b8H7Q/bz9PsP+xQ5JUnmfG/C0t9rcR+6j8Kmu3zqlizv9R7rfBCi9a/BrRIwRB25b8MuFwl4SrxvxgkCbfYmNO/wQNw9Q58AUB9ETVXa7HrPw8OYJ7iYck/lPtLt1iU2L9DklA/GeHlv/PeSlp5A6o/oqlQF2ym4j9E1I56vwv0P/YCmCYHJOi/d/j2k6Fb1r9gQXfbdGfsv3XXfmA+4cc/wOe+Z5MJ7D8eR4++89jqP6u16ZeVJOC/fvrL2LIB1r/5D5ZGSxT7P1mizB6NaQLARPaNl5bL7T8OdqOQUs0AQHZIzUrLZPc/5TaUs+wL67/usm+Jahfsvzb4ucR7otS/RFsckBNT7D/cirY9GHzEPwW+pGonG/I/plrUKqsE2L/7RgACbxTgPwF2VdYLvcq/Y+86s7zCvj95fKb/ncXiPyR77fQia9Q/hsiSuhUi5r810bxGR1bmPxxEzIPELvM/pzE7vnCyyb+AphwHrPjgP/rBO2XTvuc/hYubQ0k+2j8uLa/BWXe+P/avGpPOW+i/n74vEIga2z8tK9yS/TXTP2lweSnBR/K/zHjemjSzxz/kppe90vHtv9j8hwIM1+O/HO/t0IDg8b/oWuATFxv3vyT3vqI/dcy/UHxlkFH9+T8J2mW8IMDjP1v3NppR/eW/Tjs6CI/Msz96nGOx5e+Jv6JAX8B6cOS/y45Abesj8j8Fxo+9v+r7PxZXasjU2ew/9JpjDSt7AMAYj+VlVQHOP4gjK6QgEsa/OYndxq0vvz+SeAvPyVDyP8LEmdu7db+/UAqTgrjo579CoIcPEEfSPwwqv9R3LQDAMJevib5zzT/M2D4LFCXRv9KPVHLI5uC/hXDdt10S8j9NL3kp62/IP5QJfPjzE9O/j0NIuoyO+j/sep/EU1KmPwySK0sKnaU/sjbNPxGOyL8=\"},\"shape\":[100],\"dtype\":\"float64\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"LBLnm/DES8AkrDOq71IlwPlWT3/lwTZA4jJx+SZGWUDAjGVFzQpiQGZOpXr4pEBAYvA9ZvSBQEDIHvBtEOM5wH0lA6rn6FjACTLBFpbNN0BO18ITWstGwJiBz5FxrSDAAGGV0y/UV8B3MCJJIjRCQK5KmAS60lXAPKt5/9bqUEBgISVai18rwBk6w4eAuEvAW87CfcZVUMCYUR47kDlLwFF400nL1TzAxQw/t7haZkB3q114X0VQQBqFLJEWqzpAjV4PusSLMsAucj2R4L9EwBQBWujwYus/eFl+N+RHRkA6r0glB/9cQHrVhcqqJ1DACpyA1GfuOcDwKLLF5nBOwBvxU080uDJAvahT9nXEUkBms2TTAE1dQIhLh8HBsjbA+l6LDmkuTMCMX8o9yppmQAua3/xlEmjAthH/AzUgUUC3SLZttLBkQM1nK2cGQFpAkxx/nsSbUcAmIbmbeWJNwAsw+wCxyUTAm4+RkNJPUkDajVZDs3tEQA0gDIaQHVRAfcgANkPLPMCiLJkq9x1BQFZfAhKB20TARB71JaC1LEDAr0hVhtVTQOYV0LoTITtAZMDzpmG+Q8ALZtGCiLNQQN1wx1f54VdAQFrP7gJ9DEAAUpaaLMu7P7DWjqNlP0xALt0LyaTJSUDsaQ18f8cAwCCbnvDrpzrAVp8MQ/neQ0AUUVHb+gxCQB/GCkCG5lLANMn9YG22M0DHuHFTd+ZRwF4wf9lQ5zPAJugd6VYtU8An0BJKppVdwEVjdocZ0z3AEXmgKKbiYkCWDDdcGXZKQJxOlFmdxk3ANgGvkbK4PkBWyY6h5Vo9wFv7HiWhZEbAJOjuNLwDWUDt3hoVc9JiQBqY0egGgF5Agois5227ZsCIMnvSmMoLQDggz5rq+jbAoM/PZJaXRkCrh1UczqZYQH5oOLtGjiLAmcJJNCs9SsCCOXDp4UtDQD5oZxce/2jAWOeApVAKI8AYGWUwZscLwCyJLMz3p0HADuRN8ffZUkA6vb3D9JExQLubBsXD9TfAhsh+JcCCYEDndU6Pips0QC64vh48jklApJxxnlhOOsA=\"},\"shape\":[100],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2063\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2064\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Circle\",\"id\":\"p2059\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"radius\":{\"type\":\"value\",\"value\":0.02},\"line_color\":{\"type\":\"value\",\"value\":\"red\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"red\"},\"hatch_color\":{\"type\":\"value\",\"value\":\"red\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Circle\",\"id\":\"p2060\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"radius\":{\"type\":\"value\",\"value\":0.02},\"line_color\":{\"type\":\"value\",\"value\":\"red\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"red\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"value\",\"value\":\"red\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Circle\",\"id\":\"p2061\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"radius\":{\"type\":\"value\",\"value\":0.02},\"line_color\":{\"type\":\"value\",\"value\":\"red\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"red\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"red\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2073\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p2067\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p2068\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p2069\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"rdm3L4KT47/GI6JTXuvPv7RjuJ3hQ98/VQxURWVi6D9cGydwK1H4P/m+mUwBKtg/ANV6zOtp4D9zV3Aq2Xrlv4B8nooMWPa//ib461wz1D9AtraxRGLkvzfSmudoZNm/xq232iKc8b8H7Q/bz9PsP+xQ5JUnmfG/C0t9rcR+6j8Kmu3zqlizv9R7rfBCi9a/BrRIwRB25b8MuFwl4SrxvxgkCbfYmNO/wQNw9Q58AUB9ETVXa7HrPw8OYJ7iYck/lPtLt1iU2L9DklA/GeHlv/PeSlp5A6o/oqlQF2ym4j9E1I56vwv0P/YCmCYHJOi/d/j2k6Fb1r9gQXfbdGfsv3XXfmA+4cc/wOe+Z5MJ7D8eR4++89jqP6u16ZeVJOC/fvrL2LIB1r/5D5ZGSxT7P1mizB6NaQLARPaNl5bL7T8OdqOQUs0AQHZIzUrLZPc/5TaUs+wL67/usm+Jahfsvzb4ucR7otS/RFsckBNT7D/cirY9GHzEPwW+pGonG/I/plrUKqsE2L/7RgACbxTgPwF2VdYLvcq/Y+86s7zCvj95fKb/ncXiPyR77fQia9Q/hsiSuhUi5r810bxGR1bmPxxEzIPELvM/pzE7vnCyyb+AphwHrPjgP/rBO2XTvuc/hYubQ0k+2j8uLa/BWXe+P/avGpPOW+i/n74vEIga2z8tK9yS/TXTP2lweSnBR/K/zHjemjSzxz/kppe90vHtv9j8hwIM1+O/HO/t0IDg8b/oWuATFxv3vyT3vqI/dcy/UHxlkFH9+T8J2mW8IMDjP1v3NppR/eW/Tjs6CI/Msz96nGOx5e+Jv6JAX8B6cOS/y45Abesj8j8Fxo+9v+r7PxZXasjU2ew/9JpjDSt7AMAYj+VlVQHOP4gjK6QgEsa/OYndxq0vvz+SeAvPyVDyP8LEmdu7db+/UAqTgrjo579CoIcPEEfSPwwqv9R3LQDAMJevib5zzT/M2D4LFCXRv9KPVHLI5uC/hXDdt10S8j9NL3kp62/IP5QJfPjzE9O/j0NIuoyO+j/sep/EU1KmPwySK0sKnaU/sjbNPxGOyL8=\"},\"shape\":[100],\"dtype\":\"float64\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"+J85wuEehMF+ZTFC49CFQj9qAUPbyQxCZXM5QrRATcITRd7CNbbwQcfzQcL8X+XBnHWtwpK4nELfVq3Cp7KQQqh7C8AUAsjBZA9Nwt/lqMKon6nBY1Q4Q4XflkIISaNBvv7cwfVeUcIX6wNBMIJQQrvK1kIHsGjC/BbGwZ5SisIaiptB/aWYQpODkkLMORbCu3fCwamnD0NiyTnD7bWhQsVKMUNVT/lCAFODwv21iMKEUrTB6CCaQmkJikGVysJCWDXXwfkBNkKq0lLBxnFfQdPDUUJE9fJBAf1TwtmFdkJO5M1C0hVIwTwzP0KkhYJC6IEXQiTtXUEk72rCVfEbQs+B5kEWX7TCxJyaQa9DksJUWDzCgzawwg4g5sJijWTBeAkKQ7naW0LsgVLCLu8mQWqaQEBMhkLC9STDQjz5E0Oa15xCB+AlwwYeu0FqsiLBZqNhQZTzxEJ5o8LAikxmwlTi3EHnviLDGES4QQhXkMEWDB7C+m/CQqFpnkF0RaTBLfYMQ7LN9EAcJ/FATE88wQ==\"},\"shape\":[100],\"dtype\":\"float32\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2074\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2075\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p2070\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#1f77b4\",\"line_width\":2}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p2071\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.1,\"line_width\":2}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p2072\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"#1f77b4\",\"line_alpha\":0.2,\"line_width\":2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p2032\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p2045\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p2046\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p2047\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p2048\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p2053\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p2054\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p2055\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p2040\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p2041\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p2042\"},\"axis_label\":\"y\",\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p2043\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p2035\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p2036\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p2037\"},\"axis_label\":\"x\",\"axis_label_standoff\":10,\"axis_label_text_color\":\"#E0E0E0\",\"axis_label_text_font\":\"Helvetica\",\"axis_label_text_font_size\":\"1.25em\",\"axis_label_text_font_style\":\"normal\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p2038\"},\"major_label_text_color\":\"#E0E0E0\",\"major_label_text_font\":\"Helvetica\",\"major_label_text_font_size\":\"1.025em\",\"axis_line_color\":\"#E0E0E0\",\"axis_line_alpha\":0,\"major_tick_line_color\":\"#E0E0E0\",\"major_tick_line_alpha\":0,\"minor_tick_line_color\":\"#E0E0E0\",\"minor_tick_line_alpha\":0}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p2039\",\"attributes\":{\"axis\":{\"id\":\"p2035\"},\"grid_line_color\":\"#E0E0E0\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p2044\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p2040\"},\"grid_line_color\":\"#E0E0E0\",\"grid_line_alpha\":0.25}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p2065\",\"attributes\":{\"location\":\"top_left\",\"border_line_alpha\":0,\"background_fill_color\":\"#20262B\",\"background_fill_alpha\":0.25,\"click_policy\":\"mute\",\"label_text_color\":\"#E0E0E0\",\"label_text_font\":\"Helvetica\",\"label_text_font_size\":\"1.025em\",\"label_standoff\":8,\"glyph_width\":15,\"spacing\":8,\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p2066\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Original\"},\"renderers\":[{\"id\":\"p2062\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p2076\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"p2073\"}]}}]}}],\"background_fill_color\":\"#20262B\",\"border_fill_color\":\"#15191C\"}}]}};\n",
       "  const render_items = [{\"docid\":\"7c49a87b-b9d7-4ced-a909-87ed2d87a87c\",\"roots\":{\"p2023\":\"b436194f-d535-46f5-8f7a-6821750d91d7\"},\"root_ids\":[\"p2023\"]}];\n",
       "  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p2023"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "\n",
    "from bokeh.io import curdoc\n",
    "# apply theme to current document\n",
    "curdoc().theme = \"dark_minimal\"\n",
    "\n",
    "\n",
    "# create a new plot with a title and axis labels\n",
    "p = figure(title=\"Real data vs Model\",\n",
    "           x_axis_label='x',\n",
    "           y_axis_label='y',\n",
    "           sizing_mode=\"stretch_width\",\n",
    "           max_width=1000,\n",
    "           height=500,)\n",
    "\n",
    "\n",
    "# add a line renderer with legend and line thickness to the plot\n",
    "p.circle(x_numpy.flatten(), y_numpy.flatten(), legend_label=\"Original\", line_width=2, color=\"red\", radius=0.02)\n",
    "p.line(x_numpy.flatten(), predicted.flatten(), legend_label=\"Predicted\", line_width=2)\n",
    "\n",
    "p.legend.location = \"top_left\"\n",
    "p.legend.click_policy=\"mute\"\n",
    "\n",
    "# show the results\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2e5d4-069a-4d91-899f-8b4dbab02cdc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc5e06-804a-4a4c-86f6-9ad2d5d1c3d8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ed0a1-badf-4876-b5bd-7c52d7537290",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc = datasets.load_breast_cancer()\n",
    "bc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1c7d2-c22c-4595-828f-ca5c28ab1d3c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = bc.data, bc.target\n",
    "n_samples, n_features = x.shape\n",
    "n_samples, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7273c857-980e-441b-9514-ae91090c71b3",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1234)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48093f6d-88ed-49a3-9cde-5676fdcd93aa",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257e7f0-e8d2-4435-b90e-30542301388c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dca57a-5904-4177-b2dc-d78f51015088",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.view(y_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aaaacd-c556-48f6-b26a-20eff9334b10",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#1. model\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(n_input, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702443b6-4967-429a-8ae1-aef6dcec8bb9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#2. loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffd4c2-cec2-43c3-8003-059452b09a09",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoc:50] (y = -0.161x + 0.417)             loss:0.11979, accuracy: 92.11%, error: 7.89%,             dw:0.01399 db:-0.02377\n",
      "[epoc:100] (y = -0.211x + 0.575)             loss:0.08388, accuracy: 92.98%, error: 7.02%,             dw:0.00694 db:-0.00972\n",
      "[epoc:150] (y = -0.245x + 0.668)             loss:0.06873, accuracy: 94.74%, error: 5.26%,             dw:0.00463 db:-0.00550\n",
      "[epoc:200] (y = -0.273x + 0.732)             loss:0.05965, accuracy: 95.61%, error: 4.39%,             dw:0.00345 db:-0.00349\n",
      "[epoc:250] (y = -0.298x + 0.780)             loss:0.05347, accuracy: 95.61%, error: 4.39%,             dw:0.00273 db:-0.00234\n",
      "[epoc:300] (y = -0.320x + 0.817)             loss:0.04894, accuracy: 95.61%, error: 4.39%,             dw:0.00224 db:-0.00163\n",
      "[epoc:350] (y = -0.341x + 0.845)             loss:0.04546, accuracy: 95.61%, error: 4.39%,             dw:0.00189 db:-0.00116\n",
      "[epoc:400] (y = -0.360x + 0.867)             loss:0.04269, accuracy: 95.61%, error: 4.39%,             dw:0.00163 db:-0.00085\n",
      "[epoc:450] (y = -0.378x + 0.884)             loss:0.04042, accuracy: 95.61%, error: 4.39%,             dw:0.00142 db:-0.00063\n",
      "[epoc:500] (y = -0.395x + 0.898)             loss:0.03853, accuracy: 95.61%, error: 4.39%,             dw:0.00126 db:-0.00047\n",
      "[epoc:550] (y = -0.411x + 0.909)             loss:0.03693, accuracy: 95.61%, error: 4.39%,             dw:0.00113 db:-0.00035\n",
      "[epoc:600] (y = -0.427x + 0.918)             loss:0.03555, accuracy: 95.61%, error: 4.39%,             dw:0.00102 db:-0.00026\n",
      "[epoc:650] (y = -0.442x + 0.924)             loss:0.03434, accuracy: 95.61%, error: 4.39%,             dw:0.00092 db:-0.00018\n",
      "[epoc:700] (y = -0.456x + 0.929)             loss:0.03329, accuracy: 95.61%, error: 4.39%,             dw:0.00084 db:-0.00013\n",
      "[epoc:750] (y = -0.469x + 0.933)             loss:0.03234, accuracy: 95.61%, error: 4.39%,             dw:0.00077 db:-0.00008\n",
      "[epoc:800] (y = -0.483x + 0.935)             loss:0.03150, accuracy: 95.61%, error: 4.39%,             dw:0.00072 db:-0.00004\n",
      "[epoc:850] (y = -0.495x + 0.936)             loss:0.03073, accuracy: 95.61%, error: 4.39%,             dw:0.00066 db:-0.00001\n",
      "[epoc:900] (y = -0.508x + 0.936)             loss:0.03004, accuracy: 95.61%, error: 4.39%,             dw:0.00062 db:0.00001\n",
      "[epoc:950] (y = -0.520x + 0.935)             loss:0.02940, accuracy: 95.61%, error: 4.39%,             dw:0.00057 db:0.00003\n",
      "[epoc:1000] (y = -0.531x + 0.934)             loss:0.02881, accuracy: 95.61%, error: 4.39%,             dw:0.00054 db:0.00005\n"
     ]
    }
   ],
   "source": [
    "#3. train loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_predicted = model(x_train)\n",
    "    loss=criterion(y_predicted, y_train)\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        with torch.no_grad():\n",
    "            [w,b] = model.parameters()\n",
    "            y_predicted = model(x_test)\n",
    "            y_predicted_cls = y_predicted.round().flatten()\n",
    "            acc = (y_predicted_cls == y_test).float().mean() * 100\n",
    "            error = (100 - acc)\n",
    "            print(f'[epoc:{epoch + 1}] (y = {w.mean().item():.3f}x + {b.mean().item():.3f}) \\\n",
    "            loss:{loss.item():.5f}, accuracy: {acc:.2f}%, error: {error:.2f}%, \\\n",
    "            dw:{w.grad.mean().item():.5f} db:{b.grad.mean().item():.5f}')\n",
    "\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f614095-fc94-477c-963c-426258ea0b34",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoc:1000] (y = -0.219x + 0.270)     loss:0.08642, accuracy: 94.74%, error: 5.26%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    [w,b] = model.parameters()\n",
    "    y_predicted = model(x_test)\n",
    "    y_predicted_cls = y_predicted.round().flatten()\n",
    "    acc = (y_predicted_cls == y_test).float().mean() * 100\n",
    "    error = (100 - acc)\n",
    "    print(f'[epoc:{epoch + 1}] (y = {w.mean().item():.3f}x + {b.mean().item():.3f}) \\\n",
    "    loss:{loss.item():.5f}, accuracy: {acc:.2f}%, error: {error:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b3b93-ad7c-4d30-959f-48a99e75037e",
   "metadata": {},
   "source": [
    "## Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6880514e-6d7e-4545-887f-d0fea1a843b1",
   "metadata": {},
   "source": [
    "`Epoch`: 1 forward and backward pass of **ALL** training samples\n",
    "\n",
    "`Batchsize`: No. of training samples in one forward and backward pass\n",
    "\n",
    "`No. of iterations`: number of passes, each pass using [batchsize] number of samples\n",
    "\n",
    "e.g 100 samples, batch_size = 20 --> 100/20 = 5 iterations for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392815a8-41c5-4b4d-9983-1ff648ec69d5",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        xy = np.loadtxt('Data/wine.csv', delimiter=\",\", dtype=np.float32, skiprows = 1)\n",
    "        self.xy = xy\n",
    "        self.x = torch.from_numpy(xy[:,1:])\n",
    "        self.y = torch.from_numpy(xy[:,[0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a807f69-effa-44b4-91b2-98d73a5e4d80",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataset = WineDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe6e14-dc17-4180-97a0-9dc5ca5305c8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
       "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
       "         1.0650e+03]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data = dataset[0]\n",
    "first_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e626c3a-e9fd-4c53-a2dd-5bce360d8785",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
       "         3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
       "         1.0650e+03]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = dataset[0]\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916e6a7-bd8f-4f47-aaea-421226e527e4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size = 4, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d2861-6caa-42d1-9b24-92299e032321",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29a6d79-18da-466c-83eb-af63440f1f4b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.3680e+01, 1.8300e+00, 2.3600e+00, 1.7200e+01, 1.0400e+02, 2.4200e+00,\n",
       "          2.6900e+00, 4.2000e-01, 1.9700e+00, 3.8400e+00, 1.2300e+00, 2.8700e+00,\n",
       "          9.9000e+02],\n",
       "         [1.2160e+01, 1.6100e+00, 2.3100e+00, 2.2800e+01, 9.0000e+01, 1.7800e+00,\n",
       "          1.6900e+00, 4.3000e-01, 1.5600e+00, 2.4500e+00, 1.3300e+00, 2.2600e+00,\n",
       "          4.9500e+02],\n",
       "         [1.2510e+01, 1.7300e+00, 1.9800e+00, 2.0500e+01, 8.5000e+01, 2.2000e+00,\n",
       "          1.9200e+00, 3.2000e-01, 1.4800e+00, 2.9400e+00, 1.0400e+00, 3.5700e+00,\n",
       "          6.7200e+02],\n",
       "         [1.4200e+01, 1.7600e+00, 2.4500e+00, 1.5200e+01, 1.1200e+02, 3.2700e+00,\n",
       "          3.3900e+00, 3.4000e-01, 1.9700e+00, 6.7500e+00, 1.0500e+00, 2.8500e+00,\n",
       "          1.4500e+03]]),\n",
       " tensor([[1.],\n",
       "         [2.],\n",
       "         [2.],\n",
       "         [1.]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3c6b9-7c96-4ce4-bb69-3e72866af17e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afec69-bf4d-404e-9949-88c1dc7afae0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "data = next(dataiter)\n",
    "features, labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242d834-0490-4e06-bed8-c96dc7ae99de",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.2790e+01, 2.6700e+00, 2.4800e+00, 2.2000e+01, 1.1200e+02, 1.4800e+00,\n",
       "          1.3600e+00, 2.4000e-01, 1.2600e+00, 1.0800e+01, 4.8000e-01, 1.4700e+00,\n",
       "          4.8000e+02],\n",
       "         [1.2720e+01, 1.7500e+00, 2.2800e+00, 2.2500e+01, 8.4000e+01, 1.3800e+00,\n",
       "          1.7600e+00, 4.8000e-01, 1.6300e+00, 3.3000e+00, 8.8000e-01, 2.4200e+00,\n",
       "          4.8800e+02],\n",
       "         [1.4380e+01, 1.8700e+00, 2.3800e+00, 1.2000e+01, 1.0200e+02, 3.3000e+00,\n",
       "          3.6400e+00, 2.9000e-01, 2.9600e+00, 7.5000e+00, 1.2000e+00, 3.0000e+00,\n",
       "          1.5470e+03],\n",
       "         [1.1650e+01, 1.6700e+00, 2.6200e+00, 2.6000e+01, 8.8000e+01, 1.9200e+00,\n",
       "          1.6100e+00, 4.0000e-01, 1.3400e+00, 2.6000e+00, 1.3600e+00, 3.2100e+00,\n",
       "          5.6200e+02]]),\n",
       " tensor([[3.],\n",
       "         [2.],\n",
       "         [1.],\n",
       "         [2.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc049501-f132-4fe2-8423-0c24badb892c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 45)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "\n",
    "total_samples, n_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65838d39-379d-4ca3-a3d7-0e71b040338f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 5/45, inputs:tensor([ 11.8100,   2.1200,   2.7400,  21.5000, 134.0000]) labels:tensor([2.])\n",
      "epoch 1/2, step 10/45, inputs:tensor([ 13.2400,   2.5900,   2.8700,  21.0000, 118.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 15/45, inputs:tensor([13.4800,  1.6700,  2.6400, 22.5000, 89.0000]) labels:tensor([3.])\n",
      "epoch 1/2, step 20/45, inputs:tensor([ 12.2900,   1.6100,   2.2100,  20.4000, 103.0000]) labels:tensor([2.])\n",
      "epoch 1/2, step 25/45, inputs:tensor([ 13.5600,   1.7300,   2.4600,  20.5000, 116.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 30/45, inputs:tensor([13.5000,  1.8100,  2.6100, 20.0000, 96.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 35/45, inputs:tensor([14.0200,  1.6800,  2.2100, 16.0000, 96.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 40/45, inputs:tensor([ 13.7700,   1.9000,   2.6800,  17.1000, 115.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 45/45, inputs:tensor([12.4500,  3.0300,  2.6400, 27.0000, 97.0000]) labels:tensor([3.])\n",
      "epoch 2/2, step 5/45, inputs:tensor([14.0200,  1.6800,  2.2100, 16.0000, 96.0000]) labels:tensor([1.])\n",
      "epoch 2/2, step 10/45, inputs:tensor([ 14.2300,   1.7100,   2.4300,  15.6000, 127.0000]) labels:tensor([1.])\n",
      "epoch 2/2, step 15/45, inputs:tensor([ 13.5600,   1.7300,   2.4600,  20.5000, 116.0000]) labels:tensor([1.])\n",
      "epoch 2/2, step 20/45, inputs:tensor([12.2900,  1.4100,  1.9800, 16.0000, 85.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 25/45, inputs:tensor([ 12.8400,   2.9600,   2.6100,  24.0000, 101.0000]) labels:tensor([3.])\n",
      "epoch 2/2, step 30/45, inputs:tensor([ 14.0600,   1.6300,   2.2800,  16.0000, 126.0000]) labels:tensor([1.])\n",
      "epoch 2/2, step 35/45, inputs:tensor([12.4300,  1.5300,  2.2900, 21.5000, 86.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 40/45, inputs:tensor([12.7200,  1.7500,  2.2800, 22.5000, 84.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 45/45, inputs:tensor([13.2300,  3.3000,  2.2800, 18.5000, 98.0000]) labels:tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f'epoch {epoch + 1}/{num_epochs}, step {i+1}/{n_iterations}, inputs:{inputs[0][:5]} labels:{labels[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63fd40f-6e4f-44be-b48e-b490a0c928fd",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd51a54-344f-4970-a893-b347666871ff",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch \n",
    "from PIL import Image\n",
    "from torch import nn, save, load\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "\n",
    "# Get data \n",
    "train = torchvision.datasets.MNIST(root=\"data\", download=True, train=True, transform=torchvision.transforms.ToTensor())\n",
    "dataset = DataLoader(train, 32)\n",
    "#1,28,28 - classes 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495b63f-0f3f-4d40-81ab-6d2f6cf2b99c",
   "metadata": {},
   "source": [
    "## Dataset Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52b741-619c-439e-bae3-0a981d9c2b1e",
   "metadata": {},
   "source": [
    "### Types of Transform:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e8ae4e-7d58-4fee-8d94-860bbe3c4866",
   "metadata": {},
   "source": [
    "#### On Images:\n",
    "> CenterCrop, Grayscale, Pad, RandomAffine RandomCrop, RandomHorizontalFlip, RandomRotation Resize, Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd0be88-a78f-4c60-a663-11b5c5a26830",
   "metadata": {},
   "source": [
    "#### On Tensors:\n",
    "> LinearTransformation, Normalize, RandomErasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3a99a-98cb-4461-b02f-c76f4656c6a5",
   "metadata": {},
   "source": [
    "#### Conversion:\n",
    "> ToPILImage: from tensor or ndarray\n",
    "\n",
    "> ToTensor: from numpy.ndarray or PIL Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3c876-bdcc-45f5-a4ad-2a03a2a280c2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        #data loading\n",
    "        xy = np.loadtxt('Data/wine.csv', delimiter=\",\", dtype=np.float32, skiprows = 1)\n",
    "        self.xy = xy\n",
    "        self.x = xy[:,1:]\n",
    "        self.y = xy[:,[0]]\n",
    "        self.n_samples = xy.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06001e4e-a54e-4f7e-9569-5babdf7fe78d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class ToTensor():\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets  = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779d417-f6ca-41af-8919-90432bc70726",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b155b-d5f6-4ed1-b541-f810da857a8a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataset = WineDataset(transform = composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b355051-83c3-466f-9777-1a8465d7566c",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
       "         6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
       "         2.1300e+03]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data = dataset[0]\n",
    "first_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5329f-9816-4e73-93b0-129f8148ecd0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
       "         1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
       "         4.2600e+03]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = dataset[0]\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f65063-77ad-4d34-b19a-c3916fa4ff94",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size = 4, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144d260-815c-44c7-aaac-0d1332d9cf1b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7294c-c7c2-4064-b358-c2e6c4111e0f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2.4400e+01, 6.0600e+00, 4.6400e+00, 3.8000e+01, 1.9200e+02, 2.5000e+00,\n",
       "          9.8000e-01, 8.0000e-01, 1.4600e+00, 1.1000e+01, 1.3200e+00, 3.6600e+00,\n",
       "          1.0200e+03],\n",
       "         [2.5620e+01, 4.6200e+00, 4.8000e+00, 4.8000e+01, 1.9600e+02, 2.3000e+00,\n",
       "          2.1800e+00, 5.4000e-01, 1.6600e+00, 1.1400e+01, 1.3200e+00, 2.7200e+00,\n",
       "          1.1200e+03],\n",
       "         [1.1384e+02, 1.3680e+01, 1.9440e+01, 1.2480e+02, 1.0160e+03, 2.2400e+01,\n",
       "          2.4480e+01, 2.2400e+00, 1.8320e+01, 4.5120e+01, 8.3200e+00, 3.1360e+01,\n",
       "          8.5200e+03],\n",
       "         [2.5920e+01, 6.9000e+00, 4.7000e+00, 3.7000e+01, 2.1200e+02, 2.7800e+00,\n",
       "          1.4000e+00, 8.0000e-01, 1.8800e+00, 1.0560e+01, 1.3600e+00, 3.5000e+00,\n",
       "          1.3500e+03]]),\n",
       " tensor([[3.],\n",
       "         [3.],\n",
       "         [1.],\n",
       "         [3.]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce2ad8-a076-40da-94e6-db061f20e955",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470ad85-0906-4dfc-9478-49ea80ee2ce2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "data = next(dataiter)\n",
    "features, labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ced5f-ee20-4333-b55b-807e7bad5eff",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.7720e+01, 2.7000e+00, 4.5400e+00, 3.2000e+01, 1.9600e+02, 5.9600e+00,\n",
       "          6.3000e+00, 4.4000e-01, 3.7000e+00, 1.4440e+01, 2.0200e+00, 7.1000e+00,\n",
       "          2.0900e+03],\n",
       "         [2.7420e+01, 3.7200e+00, 4.7200e+00, 3.3200e+01, 2.0200e+02, 5.2200e+00,\n",
       "          5.7600e+00, 5.4000e-01, 3.3800e+00, 7.6000e+00, 2.2200e+00, 8.0000e+00,\n",
       "          2.0700e+03],\n",
       "         [2.5680e+01, 5.9200e+00, 5.2200e+00, 4.8000e+01, 2.0200e+02, 4.6400e+00,\n",
       "          1.2000e+00, 1.0600e+00, 1.6200e+00, 9.8400e+00, 1.7800e+00, 4.3000e+00,\n",
       "          1.1800e+03],\n",
       "         [2.6980e+01, 3.3200e+00, 4.4800e+00, 4.8000e+01, 1.7400e+02, 3.7600e+00,\n",
       "          3.6800e+00, 5.4000e-01, 2.0600e+00, 7.4800e+00, 1.9600e+00, 5.5600e+00,\n",
       "          9.4400e+02]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [3.],\n",
       "         [2.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab06a9-2643-4fb6-b500-930441777881",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 45)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "\n",
    "total_samples, n_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163b74f-11c1-41a0-9e53-fe6a2058003e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 5/45, inputs:tensor([ 25.6800,   5.9200,   5.2200,  48.0000, 202.0000]) labels:tensor([3.])\n",
      "epoch 1/2, step 10/45, inputs:tensor([ 26.9600,   3.3400,   5.2800,  45.0000, 178.0000]) labels:tensor([3.])\n",
      "epoch 1/2, step 15/45, inputs:tensor([ 28.0400,   3.3600,   4.4200,  32.0000, 192.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 20/45, inputs:tensor([ 23.6800,   5.7800,   4.4600,  36.0000, 224.0000]) labels:tensor([2.])\n",
      "epoch 1/2, step 25/45, inputs:tensor([ 28.2000,   4.0400,   4.8000,  37.6000, 206.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 30/45, inputs:tensor([ 24.8400,   5.1000,   4.5400,  44.0000, 180.0000]) labels:tensor([2.])\n",
      "epoch 1/2, step 35/45, inputs:tensor([ 27.4800,   3.3400,   4.5000,  32.8000, 236.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 40/45, inputs:tensor([ 27.3600,   3.6600,   4.7200,  34.4000, 208.0000]) labels:tensor([1.])\n",
      "epoch 1/2, step 45/45, inputs:tensor([ 26.9600,   3.6200,   4.8200,  41.0000, 200.0000]) labels:tensor([1.])\n",
      "epoch 2/2, step 5/45, inputs:tensor([ 25.4000,   7.1000,   4.7200,  43.0000, 212.0000]) labels:tensor([3.])\n",
      "epoch 2/2, step 10/45, inputs:tensor([ 24.5800,   2.8200,   3.9600,  32.0000, 170.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 15/45, inputs:tensor([ 26.4800,   5.1800,   5.7400,  42.0000, 236.0000]) labels:tensor([1.])\n",
      "epoch 2/2, step 20/45, inputs:tensor([ 25.3800,   3.0600,   4.5200,  41.4000, 160.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 25/45, inputs:tensor([ 24.5800,   6.3400,   4.4200,  36.0000, 176.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 30/45, inputs:tensor([ 24.4200,   2.3800,   3.5000,  33.6000, 302.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 35/45, inputs:tensor([ 23.1200,   4.1000,   6.4600,  57.0000, 238.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 40/45, inputs:tensor([ 24.8400,   8.8600,   5.4600,  53.0000, 204.0000]) labels:tensor([2.])\n",
      "epoch 2/2, step 45/45, inputs:tensor([ 25.2000,   2.6800,   3.8000,  37.0000, 176.0000]) labels:tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f'epoch {epoch + 1}/{num_epochs}, step {i+1}/{n_iterations}, inputs:{inputs[0][:5]} labels:{labels[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64240e4-963a-441c-9715-3e3c23b5bd57",
   "metadata": {},
   "source": [
    "## Softmax and Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91fa7a-b73b-4c8e-8e7d-2a1d783b940b",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "> $S(y_i) = \\frac{e^{y_i}}{\\sum e^{y_i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17765827-fc70-48e9-8a12-ab071ec6958e",
   "metadata": {},
   "source": [
    "$Linear = [2.0, 1.0, 0.1]$\n",
    "\n",
    "$Softmax = [0.7, 0.2, 0.1]$\n",
    "\n",
    "\n",
    "**Adds to 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf82fa9-05bc-46bb-b7ee-d695271d41a3",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65900114, 0.24243297, 0.09856589])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis = 0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fecc7-559a-4b8e-8a46-255a7f532568",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 1.0000, 0.1000], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211c251-ce4b-425f-85a0-c76651a4038a",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6590, 0.2424, 0.0986], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = torch.softmax(x, dim = 0)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccebd2-0b04-41eb-b839-27d06ff22dc5",
   "metadata": {},
   "source": [
    "## Cross Entropy\n",
    "\n",
    "> $D(\\hat{Y}, Y) = \\dfrac{1}{N} \\cdot \\displaystyle\\sum_{i=1}^{N} Y_i \\cdot \\log{\\hat{Y_i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b420f-1a95-4e23-aa58-5b525f95c604",
   "metadata": {},
   "source": [
    "$Y = [1, 0, 0]$\n",
    "\n",
    "$\\hat{Y} = [0.7, 0.2, 0.1]  --> D(\\hat{Y}, Y) = 0.35$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196221c8-5303-4fb5-b773-02197f56a57a",
   "metadata": {},
   "source": [
    "$Y = [1, 0, 0]$\n",
    "\n",
    "$\\hat{Y} = [0.7, 0.2, 0.1]  --> D(\\hat{Y}, Y) = 2.30$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748f158-095f-4217-882d-ee3e1658bf5f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd493e-09ee-461b-8de7-dded3aff29cb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "Y_actual = np.array([1,0,0])\n",
    "\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "\n",
    "l1 = cross_entropy(Y_actual, Y_pred_good)\n",
    "l2 = cross_entropy(Y_actual, Y_pred_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1173851-eee5-4111-bf17-7cbda309aafd",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good pred:0.356675, bad pred:2.3026\n"
     ]
    }
   ],
   "source": [
    "print(f'good pred:{l1:4f}, bad pred:{l2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf750f-0e6d-492c-b049-7436f81864da",
   "metadata": {},
   "source": [
    "### nn.CrossEntropyLoss()\n",
    "\n",
    "> applies nn.LogSoftmax + nn.NLLLoss(negative log likelihood loss)\n",
    "\n",
    "> y has class labels, not One-Hot!\n",
    "\n",
    "> Y_pred has raw scores(logits), no softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a12a8a-60a7-49ad-924b-0b12920c8514",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989b53c-9cea-45fe-a9e9-6d5e50dadf9d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good pred:0.417030, bad pred:1.8406\n"
     ]
    }
   ],
   "source": [
    "Y = torch.tensor([0])\n",
    "\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'good pred:{l1:4f}, bad pred:{l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198fc23-1e58-4dd9-b7fc-7d7e02fdab28",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good pred:tensor([0]), bad pred:tensor([1])\n"
     ]
    }
   ],
   "source": [
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print(f'good pred:{predictions1}, bad pred:{predictions2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d06375-bc59-4380-9ede-dc01b5456539",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#Multiclass Problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.rely = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded78578-d6eb-4efc-aeec-89600d7fd71d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "model = NeuralNet2(input_size = 28 * 28, hidden_size = 5, num_classes = 3)\n",
    "crioterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54bd46a-cdec-4cc3-9392-f0dc205500eb",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "> Without activation functions, our network is basically just a stacked linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151ef77-7b82-4e7d-815f-3d015e5f975f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f909bfe-5fc4-4bf1-8aa2-ecc84cb67608",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#Option 1 (create nn modules)\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7064c-97ca-4e13-bd0c-006a6e6f65e4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#Option 2 (use activation functions directly in forward pass)\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0211a-a687-44d6-bb3f-346bce62a10c",
   "metadata": {},
   "source": [
    "## MLP on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e9c86-fd5b-4ce2-b8a0-6116275d0ffe",
   "metadata": {},
   "source": [
    "- MNIST\n",
    "- DataLoader, Transformation\n",
    "- Multilayer Neural Net, activation function\n",
    "- Loss and Optimizer\n",
    "- Training Loop (batch training)\n",
    "- Model evaluation\n",
    "- GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbe5e4-30b9-404c-9d1d-9b2e7ea1c47c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c92cf7-f28c-4d8d-b74a-986ae73ba090",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4818a90-c611-4969-a463-0707bbf0043b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d80a16-013a-47b2-9aa6-6e440864d1f6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de61ed-d21a-4f94-8b85-298392df2302",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\",\n",
    "                                           download=True,\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\",\n",
    "                                          download=True,\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb49bc-6262-4800-a2cd-3a2b5f8dbb9d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7a957-87fa-44f3-95fd-7c6a58491632",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_dataset[1]\n",
    "plt.imshow(transforms.ToPILImage()(image), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b54185-b200-4479-a439-e3e288d28854",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "examples = iter(train_loader)\n",
    "images, labels = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bf0dc-fa00-4d46-848e-a319e4fb9c8e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1, 28, 28]), torch.Size([100]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315c6b3-45b6-4d90-9bb0-4e62ff593f75",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(images[i][0], cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9de21-e70f-458a-b7b4-b9f8bd5201a9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b209da-ae25-4945-8c26-6217f720bb4f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ac4d8-6314-42b0-ab88-14aeb10e8001",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:1/2, [step:100/600] loss:0.1501 accuracy:95.75166666666667\n",
      "[epoch:1/2, [step:200/600] loss:0.1416 accuracy:95.87833333333333\n",
      "[epoch:1/2, [step:300/600] loss:0.1484 accuracy:96.32\n",
      "[epoch:1/2, [step:400/600] loss:0.1528 accuracy:96.335\n",
      "[epoch:1/2, [step:500/600] loss:0.1360 accuracy:96.65166666666667\n",
      "[epoch:1/2, [step:600/600] loss:0.1210 accuracy:96.815\n",
      "[epoch:2/2, [step:100/600] loss:0.1129 accuracy:96.69333333333333\n",
      "[epoch:2/2, [step:200/600] loss:0.1101 accuracy:97.1\n",
      "[epoch:2/2, [step:300/600] loss:0.1209 accuracy:97.175\n",
      "[epoch:2/2, [step:400/600] loss:0.1051 accuracy:97.15833333333333\n",
      "[epoch:2/2, [step:500/600] loss:0.1082 accuracy:97.27666666666667\n",
      "[epoch:2/2, [step:600/600] loss:0.1099 accuracy:97.445\n"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "n_total_steps = len(train_loader)\n",
    "running_loss = 0.0\n",
    "print_stat = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28 --> 100 , 28 * 28\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % print_stat == 0:\n",
    "            with torch.no_grad():\n",
    "                n_correct = 0\n",
    "                n_samples = 0\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.reshape(-1, 28 * 28).to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    n_samples += labels.shape[0]\n",
    "                    n_correct += (predictions == labels).sum().item()\n",
    "            \n",
    "                acc = 100.0 * n_correct / n_samples\n",
    "            \n",
    "            print(f'[epoch:{epoch+1}/{num_epochs}, [step:{i+1}/{n_total_steps}] loss:{(running_loss/print_stat):.4f} accuracy:{acc}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4127a-0692-48aa-b864-5fa33def6bc8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 95.76\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16eebf-2cc8-4571-9a0d-14cb36cbd99e",
   "metadata": {},
   "source": [
    "## CNN on Cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89397482-7b07-4e06-832a-b3b8d60b1988",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71fca37-1076-4dca-91f1-252e1b071cb0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52a640-dc49-46ae-938b-6e8283ed268e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d8a00-c15a-495a-965f-bda1d165c984",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "batch_size = 100\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042b1f6-2178-4a0a-8f51-27df3fcbecda",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", \n",
    "                                             download=True,\n",
    "                                             train=True,\n",
    "                                             transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\",\n",
    "                                            download=True,\n",
    "                                            train=False,\n",
    "                                            transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca27339-8aa0-4fa0-a409-4dae0d5fd3db",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6e8ff-1157-476c-bfcd-e8c96c9813d4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "classes = train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46110123-d625-4642-aa32-dc3ee4d384b3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "classes = list(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d02228-f453-4489-8a80-57587e1fc7c5",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd0e18-9ec9-4183-9a59-0ee22f898d3c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "examples = iter(train_loader)\n",
    "images, labels = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0f3d7-5df6-427b-865a-06a33f81e2c0",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3, 32, 32]), torch.Size([100]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818ba06-5d05-4635-a4d6-91955f293eec",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # input size: 3 colour channels\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 40)\n",
    "        self.fc3 = nn.Linear(40, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool(F.relu(self.conv1(x)))\n",
    "        out = self.pool(F.relu(self.conv2(out)))\n",
    "        out = out.view(-1, 16*5*5)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out\n",
    "        \n",
    "\n",
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0122073-014b-4d8d-953a-101e5f7d6a7b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14ce76-7acf-4ab1-9ce4-210a54014545",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Image Classifier Neural Network\n",
    "class ImageClassifier(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3,3)), \n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(64*(28-2)*(28-2), 10)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.model(x)\n",
    "\n",
    "model = ImageClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35d8cd-2f15-4103-ac13-099af73db70d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:1/4, [step:100/500] loss:2.3026 accuracy:11.686\n",
      "[epoch:1/4, [step:200/500] loss:2.3022 accuracy:11.686\n",
      "[epoch:1/4, [step:300/500] loss:2.3026 accuracy:11.686\n",
      "[epoch:1/4, [step:400/500] loss:2.3025 accuracy:11.686\n",
      "[epoch:1/4, [step:500/500] loss:2.3024 accuracy:11.686\n",
      "[epoch:2/4, [step:100/500] loss:2.3026 accuracy:11.686\n",
      "[epoch:2/4, [step:200/500] loss:2.3024 accuracy:11.686\n",
      "[epoch:2/4, [step:300/500] loss:2.3024 accuracy:11.686\n",
      "[epoch:2/4, [step:400/500] loss:2.3022 accuracy:11.686\n",
      "[epoch:2/4, [step:500/500] loss:2.3027 accuracy:11.686\n",
      "[epoch:3/4, [step:100/500] loss:2.3023 accuracy:11.686\n",
      "[epoch:3/4, [step:200/500] loss:2.3022 accuracy:11.686\n",
      "[epoch:3/4, [step:300/500] loss:2.3026 accuracy:11.686\n",
      "[epoch:3/4, [step:400/500] loss:2.3026 accuracy:11.686\n",
      "[epoch:3/4, [step:500/500] loss:2.3025 accuracy:11.686\n",
      "[epoch:4/4, [step:100/500] loss:2.3025 accuracy:11.686\n",
      "[epoch:4/4, [step:200/500] loss:2.3025 accuracy:11.686\n",
      "[epoch:4/4, [step:300/500] loss:2.3024 accuracy:11.686\n",
      "[epoch:4/4, [step:400/500] loss:2.3024 accuracy:11.686\n",
      "[epoch:4/4, [step:500/500] loss:2.3024 accuracy:11.686\n"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "n_total_steps = len(train_loader)\n",
    "running_loss = 0.0\n",
    "print_stat = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28 --> 100 , 28 * 28\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % print_stat == 0:\n",
    "            with torch.no_grad():\n",
    "                n_correct = 0\n",
    "                n_samples = 0\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    n_samples += labels.shape[0]\n",
    "                    n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "                acc = 100.0 * n_correct / n_samples\n",
    "            \n",
    "            print(f'[epoch:{epoch+1}/{num_epochs}, [step:{i+1}/{n_total_steps}] loss:{(running_loss/print_stat):.4f} accuracy:{acc}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856a362-0654-42c3-ae8c-d6a7b8ab9e81",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f6a49-75db-477e-a018-75e216608ce8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd0791-c024-4710-a66b-9aed38a36ffe",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a770d3ab-c846-4882-927f-4f5852356fb9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:1/4, [step:100/500] loss:2.3058 accuracy:9.184\n",
      "[epoch:1/4, [step:200/500] loss:2.3051 accuracy:9.29\n",
      "[epoch:1/4, [step:300/500] loss:2.3052 accuracy:9.316\n",
      "[epoch:1/4, [step:400/500] loss:2.3056 accuracy:9.418\n",
      "[epoch:1/4, [step:500/500] loss:2.3055 accuracy:9.474\n",
      "[epoch:2/4, [step:100/500] loss:2.3042 accuracy:9.59\n",
      "[epoch:2/4, [step:200/500] loss:2.3041 accuracy:9.636\n",
      "[epoch:2/4, [step:300/500] loss:2.3038 accuracy:9.642\n",
      "[epoch:2/4, [step:400/500] loss:2.3041 accuracy:9.686\n",
      "[epoch:2/4, [step:500/500] loss:2.3041 accuracy:9.83\n",
      "[epoch:3/4, [step:100/500] loss:2.3031 accuracy:9.836\n",
      "[epoch:3/4, [step:200/500] loss:2.3028 accuracy:9.938\n",
      "[epoch:3/4, [step:300/500] loss:2.3013 accuracy:9.99\n",
      "[epoch:3/4, [step:400/500] loss:2.3030 accuracy:10.022\n",
      "[epoch:3/4, [step:500/500] loss:2.3034 accuracy:10.088\n",
      "[epoch:4/4, [step:100/500] loss:2.3020 accuracy:10.126\n",
      "[epoch:4/4, [step:200/500] loss:2.3015 accuracy:10.196\n",
      "[epoch:4/4, [step:300/500] loss:2.3013 accuracy:10.258\n",
      "[epoch:4/4, [step:400/500] loss:2.3018 accuracy:10.36\n",
      "[epoch:4/4, [step:500/500] loss:2.3004 accuracy:10.428\n"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "n_total_steps = len(train_loader)\n",
    "running_loss = 0.0\n",
    "print_stat = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % print_stat == 0:\n",
    "            with torch.no_grad():\n",
    "                n_correct = 0\n",
    "                n_samples = 0\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    n_samples += labels.shape[0]\n",
    "                    n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "                acc = 100.0 * n_correct / n_samples\n",
    "            \n",
    "            print(f'[epoch:{epoch+1}/{num_epochs}, [step:{i+1}/{n_total_steps}] loss:{(running_loss/print_stat):.4f} accuracy:{acc}')\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac9e2c-c89c-4e21-bc45-69deaa742f99",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
