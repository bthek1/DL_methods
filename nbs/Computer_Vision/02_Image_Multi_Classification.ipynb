{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61675874-efaf-407f-a1cf-3ff41210a846",
   "metadata": {},
   "source": [
    "# Image Multi Classification\n",
    "\n",
    "> The task of assigning multiple labels to an entire image, indicating what object or scene is present in the image.\n",
    "\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348a706-0c13-474e-a5ec-0e5bfde65e0a",
   "metadata": {},
   "source": [
    "## Popular Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f987c7-829b-4b33-88f4-c17997dc45d4",
   "metadata": {},
   "source": [
    "1. CIFAR-10\n",
    "- **Description**: 60,000 32x32 color images in 10 classes, with 6,000 images per class.\n",
    "- **URL**: [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "2. CIFAR-100\n",
    "- **Description**: 60,000 32x32 color images in 100 classes, with 600 images per class.\n",
    "- **URL**: [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "3. ImageNet\n",
    "- **Description**: Over 14 million images categorized into over 20,000 classes.\n",
    "- **URL**: [ImageNet](http://www.image-net.org/)\n",
    "\n",
    "4. MNIST\n",
    "- **Description**: 70,000 28x28 grayscale images of handwritten digits in 10 classes.\n",
    "- **URL**: [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "5. Fashion-MNIST\n",
    "- **Description**: 70,000 28x28 grayscale images of 10 fashion categories.\n",
    "- **URL**: [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef1f64-4864-4cc6-a68d-3c3629bcdacc",
   "metadata": {},
   "source": [
    "## Popular Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2b26c-b55b-4337-b870-2b5b57519e5d",
   "metadata": {},
   "source": [
    "1. Convolutional Neural Networks (CNNs)\n",
    "- **Examples**: LeNet, AlexNet, VGG, ResNet, DenseNet\n",
    "\n",
    "2. Residual Networks (ResNet)\n",
    "- **Description**: Introduces skip connections to prevent vanishing gradients.\n",
    "- **URL**: [ResNet](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "3. DenseNet\n",
    "- **Description**: Connects each layer to every other layer in a feed-forward fashion.\n",
    "- **URL**: [DenseNet](https://arxiv.org/abs/1608.06993)\n",
    "\n",
    "4. Inception Networks (GoogLeNet)\n",
    "- **Description**: Uses multiple types of convolutions in parallel to capture different features.\n",
    "- **URL**: [Inception](https://arxiv.org/abs/1409.4842)\n",
    "\n",
    "5. EfficientNet\n",
    "- **Description**: Scales up model size while balancing network depth, width, and resolution.\n",
    "- **URL**: [EfficientNet](https://arxiv.org/abs/1905.11946)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d8ee0-3468-44fa-8ab6-1cc23b0390c5",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefd0a6-bbec-4aa3-84c6-31b910305644",
   "metadata": {},
   "source": [
    "1. Learning Rate\n",
    "- **Description**: Controls how much to change the model in response to the estimated error each time the model weights are updated.\n",
    "\n",
    "2. Batch Size\n",
    "- **Description**: The number of training examples utilized in one iteration.\n",
    "\n",
    "3. Number of Epochs\n",
    "- **Description**: The number of complete passes through the training dataset.\n",
    "\n",
    "4. Optimizer\n",
    "- **Examples**: SGD, Adam, RMSprop\n",
    "\n",
    "5. Weight Initialization\n",
    "- **Examples**: Xavier, He initialization\n",
    "\n",
    "6. Dropout Rate\n",
    "- **Description**: Fraction of the input units to drop.\n",
    "\n",
    "7. Learning Rate Decay\n",
    "- **Description**: Reduces the learning rate as training progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6da196-e7d6-4d1b-9680-a95d75e6b712",
   "metadata": {},
   "source": [
    "## Popular Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4f083-a191-4241-868d-a4250735fd2e",
   "metadata": {},
   "source": [
    "1. Cross-Entropy Loss\n",
    "- **Description**: Measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
    "\n",
    "2. Hinge Loss\n",
    "- **Description**: Used for \"maximum-margin\" classification, mostly for SVMs.\n",
    "\n",
    "3. Kullback-Leibler Divergence Loss\n",
    "- **Description**: Measures how one probability distribution diverges from a second, expected probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282c363-f546-4050-9aa1-306391a892c8",
   "metadata": {},
   "source": [
    "## Popular Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ee4f3-0ada-4bea-9ac4-eda4487c1aa1",
   "metadata": {},
   "source": [
    "1. Accuracy\n",
    "- **Description**: The ratio of correctly predicted observation to the total observations.\n",
    "\n",
    "2. Precision\n",
    "- **Description**: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "\n",
    "3. Recall (Sensitivity)\n",
    "- **Description**: The ratio of correctly predicted positive observations to the all observations in actual class.\n",
    "\n",
    "4. F1 Score\n",
    "- **Description**: The weighted average of Precision and Recall.\n",
    "\n",
    "5. Confusion Matrix\n",
    "- **Description**: A table used to describe the performance of a classification model.\n",
    "\n",
    "6. ROC-AUC\n",
    "- **Description**: A graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc97849-aef6-4b8a-ad14-6b82a0209a47",
   "metadata": {},
   "source": [
    "## Other Important Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03108b8-5048-4a49-9fd0-1c375a575549",
   "metadata": {},
   "source": [
    "1. Data Augmentation\n",
    "- **Description**: Techniques used to increase the diversity of your training data without actually collecting new data.\n",
    "- **Examples**: Rotation, Translation, Scaling, Flipping, Adding Noise\n",
    "\n",
    "2. Transfer Learning\n",
    "- **Description**: Reusing a pre-trained model on a new problem.\n",
    "- **Example**: Fine-tuning a model pre-trained on ImageNet for a new classification task.\n",
    "\n",
    "3. Regularization Techniques\n",
    "- **Examples**: L1/L2 regularization, Dropout, Early Stopping\n",
    "\n",
    "4. Ensemble Methods\n",
    "- **Description**: Combining the predictions of multiple models to improve generalizability and robustness.\n",
    "- **Examples**: Bagging, Boosting, Stacking\n",
    "\n",
    "5. Fine-Tuning\n",
    "- **Description**: Adjusting the parameters of an existing model to better fit the new data.\n",
    "\n",
    "6. Hyperparameter Tuning\n",
    "- **Techniques**: Grid Search, Random Search, Bayesian Optimization\n",
    "\n",
    "7. Model Interpretability\n",
    "- **Techniques**: SHAP values, LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae975cf-5a28-4e10-8e6b-e1395e43eef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
