{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32a72b4-daaf-43eb-a851-605e9b4f9a8b",
   "metadata": {},
   "source": [
    "# Ollama\n",
    "\n",
    "> Ollama is a lightweight, extensible framework designed for building and running large language models (LLMs) on local machines. It provides a command-line interface (CLI) that facilitates model management, customization, and interaction. Here's a comprehensive guide to using Ollama, including essential commands and examples.\n",
    "\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d25416-0ed7-4f85-bf3c-bdbc07a44dc0",
   "metadata": {},
   "source": [
    "## **1. Installation**\n",
    "\n",
    "- **For Linux:**\n",
    "\n",
    "  Open your terminal and execute:\n",
    "\n",
    "  ```bash\n",
    "  curl -fsSL https://ollama.com/install.sh | sh\n",
    "  ```\n",
    "\n",
    "  This command downloads and installs Ollama on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aea2e0-1da6-4bd6-8a3a-22af6a9d8138",
   "metadata": {},
   "source": [
    "## **2. System Requirements**\n",
    "\n",
    "- **Operating System:** macOS or Linux\n",
    "- **Memory (RAM):** Minimum 8GB; 16GB or more recommended\n",
    "- **Storage:** At least 10GB of free space\n",
    "- **Processor:** Modern CPU from the last 5 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fb26e-0997-41f9-8c81-2121ccd768c6",
   "metadata": {},
   "source": [
    "## **3. Basic CLI Commands**\n",
    "\n",
    "- **Start the Ollama Server:**\n",
    "\n",
    "  To run Ollama without the desktop application:\n",
    "\n",
    "  ```bash\n",
    "  ollama serve\n",
    "  ```\n",
    "\n",
    "- **Download a Model:**\n",
    "\n",
    "  To download a specific model:\n",
    "\n",
    "  ```bash\n",
    "  ollama pull <model-name>\n",
    "  ```\n",
    "\n",
    "  Replace `<model-name>` with the desired model's name, e.g., `llama3.2`.\n",
    "\n",
    "- **List Downloaded Models:**\n",
    "\n",
    "  To view all models available on your system:\n",
    "\n",
    "  ```bash\n",
    "  ollama list\n",
    "  ```\n",
    "\n",
    "- **Run a Model:**\n",
    "\n",
    "  To start a model and enter an interactive session:\n",
    "\n",
    "  ```bash\n",
    "  ollama run <model-name>\n",
    "  ```\n",
    "\n",
    "  For example:\n",
    "\n",
    "  ```bash\n",
    "  ollama run llama3.2\n",
    "  ```\n",
    "\n",
    "- **Stop a Running Model:**\n",
    "\n",
    "  To stop a specific model:\n",
    "\n",
    "  ```bash\n",
    "  ollama stop <model-name>\n",
    "  ```\n",
    "\n",
    "- **Remove a Model:**\n",
    "\n",
    "  To delete a model from your system:\n",
    "\n",
    "  ```bash\n",
    "  ollama rm <model-name>\n",
    "  ```\n",
    "\n",
    "- **Display Model Information:**\n",
    "\n",
    "  To view details about a specific model:\n",
    "\n",
    "  ```bash\n",
    "  ollama show <model-name>\n",
    "  ```\n",
    "\n",
    "- **List Running Models:**\n",
    "\n",
    "  To see which models are currently active:\n",
    "\n",
    "  ```bash\n",
    "  ollama ps\n",
    "  ```\n",
    "\n",
    "- **Access Help:**\n",
    "\n",
    "  For a list of available commands and their descriptions:\n",
    "\n",
    "  ```bash\n",
    "  ollama help\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8b786-4f0e-4d8e-a1cc-d749ce96b14b",
   "metadata": {},
   "source": [
    "## **4. Model Customization**\n",
    "\n",
    "Ollama allows users to customize models using a `Modelfile`. This file specifies the base model and any modifications, such as system prompts or parameters.\n",
    "\n",
    "- **Create a `Modelfile`:**\n",
    "\n",
    "  Create a file named `Modelfile` with the following content:\n",
    "\n",
    "  ```\n",
    "  FROM llama3.2\n",
    "\n",
    "  SYSTEM \"You are an AI assistant specializing in environmental science. Answer all questions with a focus on sustainability.\"\n",
    "\n",
    "  PARAMETER temperature 0.7\n",
    "  ```\n",
    "\n",
    "- **Build the Custom Model:**\n",
    "\n",
    "  Use the `ollama create` command to build the model:\n",
    "\n",
    "  ```bash\n",
    "  ollama create my_custom_model -f ./Modelfile\n",
    "  ```\n",
    "\n",
    "- **Run the Custom Model:**\n",
    "\n",
    "  Start the customized model:\n",
    "\n",
    "  ```bash\n",
    "  ollama run my_custom_model\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fbfea8-0142-49f5-b09a-2ec3dde0f486",
   "metadata": {},
   "source": [
    "## **5. Using Ollama with Files**\n",
    "\n",
    "- **Summarize Text from a File:**\n",
    "\n",
    "  To summarize the content of `input.txt`:\n",
    "\n",
    "  ```bash\n",
    "  ollama run llama3.2 \"Summarize the content of this file.\" < input.txt\n",
    "  ```\n",
    "\n",
    "- **Save Model Responses to a File:**\n",
    "\n",
    "  To save the model's response to `output.txt`:\n",
    "\n",
    "  ```bash\n",
    "  ollama run llama3.2 \"Explain the concept of quantum computing.\" > output.txt\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb3949-a71a-4a6c-bd41-f60665a55272",
   "metadata": {},
   "source": [
    "## **6. Common Use Cases**\n",
    "\n",
    "- **Text Generation:**\n",
    "\n",
    "  - *Content Creation:*\n",
    "\n",
    "    Generate an article on a specific topic:\n",
    "\n",
    "    ```bash\n",
    "    ollama run llama3.2 \"Write a short article on the benefits of renewable energy.\" > article.txt\n",
    "    ```\n",
    "\n",
    "  - *Question Answering:*\n",
    "\n",
    "    Answer specific queries:\n",
    "\n",
    "    ```bash\n",
    "    ollama run llama3.2 \"What are the latest advancements in artificial intelligence?\"\n",
    "    ```\n",
    "\n",
    "- **Data Analysis:**\n",
    "\n",
    "  - *Sentiment Analysis:*\n",
    "\n",
    "    Analyze the sentiment of a given text:\n",
    "\n",
    "    ```bash\n",
    "    ollama run llama3.2 \"Determine the sentiment of this review: 'The product exceeded my expectations.'\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea66d3-aa27-44f6-9870-e1556e16ba79",
   "metadata": {},
   "source": [
    "## **7. Python Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73633df6-5396-4b58-b190-289fe2a22a8d",
   "metadata": {},
   "source": [
    "### Ollama Python Library\n",
    "\n",
    "The Ollama Python library provides the easiest way to integrate Python 3.8+ projects with [Ollama](https://github.com/ollama/ollama)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2164a91-b651-4937-be63-db837e2ef2a4",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "- [Ollama](https://ollama.com/download) should be installed and running\n",
    "- Pull a model to use with the library: `ollama pull <model>` e.g. `ollama pull llama3.2`\n",
    "  - See [Ollama.com](https://ollama.com/search) for more information on the models available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621fda2-7304-4da2-8b09-1047d8a062ad",
   "metadata": {},
   "source": [
    "### Install\n",
    "\n",
    "```sh\n",
    "pip install ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e4941-305e-405b-aabc-db9969f7f439",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "```python\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)\n",
    "```\n",
    "\n",
    "See [_types.py](ollama/_types.py) for more information on the response types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de768f-e0ac-454e-a9e7-884b84fd7cc0",
   "metadata": {},
   "source": [
    "### Streaming responses\n",
    "\n",
    "Response streaming can be enabled by setting `stream=True`.\n",
    "\n",
    "```python\n",
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model='llama3.2',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffbac4-7d00-4154-9efd-143488c852c6",
   "metadata": {},
   "source": [
    "### Custom client\n",
    "A custom client can be created by instantiating `Client` or `AsyncClient` from `ollama`.\n",
    "\n",
    "All extra keyword arguments are passed into the [`httpx.Client`](https://www.python-httpx.org/api/#client).\n",
    "\n",
    "```python\n",
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")\n",
    "response = client.chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c0a0c-0266-444e-befa-e1254554d4f2",
   "metadata": {},
   "source": [
    "### Async client\n",
    "\n",
    "The `AsyncClient` class is used to make asynchronous requests. It can be configured with the same fields as the `Client` class.\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "\n",
    "async def chat():\n",
    "  message = {'role': 'user', 'content': 'Why is the sky blue?'}\n",
    "  response = await AsyncClient().chat(model='llama3.2', messages=[message])\n",
    "\n",
    "asyncio.run(chat())\n",
    "```\n",
    "\n",
    "Setting `stream=True` modifies functions to return a Python asynchronous generator:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "\n",
    "async def chat():\n",
    "  message = {'role': 'user', 'content': 'Why is the sky blue?'}\n",
    "  async for part in await AsyncClient().chat(model='llama3.2', messages=[message], stream=True):\n",
    "    print(part['message']['content'], end='', flush=True)\n",
    "\n",
    "asyncio.run(chat())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae65c53-4924-49e1-a05f-5ebce1cb821b",
   "metadata": {},
   "source": [
    "### API\n",
    "\n",
    "The Ollama Python library's API is designed around the [Ollama REST API](https://github.com/ollama/ollama/blob/main/docs/api.md)\n",
    "\n",
    "#### Chat\n",
    "\n",
    "```python\n",
    "ollama.chat(model='llama3.2', messages=[{'role': 'user', 'content': 'Why is the sky blue?'}])\n",
    "```\n",
    "\n",
    "#### Generate\n",
    "\n",
    "```python\n",
    "ollama.generate(model='llama3.2', prompt='Why is the sky blue?')\n",
    "```\n",
    "\n",
    "#### List\n",
    "\n",
    "```python\n",
    "ollama.list()\n",
    "```\n",
    "\n",
    "#### Show\n",
    "\n",
    "```python\n",
    "ollama.show('llama3.2')\n",
    "```\n",
    "\n",
    "#### Create\n",
    "\n",
    "```python\n",
    "ollama.create(model='example', from_='llama3.2', system=\"You are Mario from Super Mario Bros.\")\n",
    "```\n",
    "\n",
    "#### Copy\n",
    "\n",
    "```python\n",
    "ollama.copy('llama3.2', 'user/llama3.2')\n",
    "```\n",
    "\n",
    "#### Delete\n",
    "\n",
    "```python\n",
    "ollama.delete('llama3.2')\n",
    "```\n",
    "\n",
    "#### Pull\n",
    "\n",
    "```python\n",
    "ollama.pull('llama3.2')\n",
    "```\n",
    "\n",
    "#### Push\n",
    "\n",
    "```python\n",
    "ollama.push('user/llama3.2')\n",
    "```\n",
    "\n",
    "#### Embed\n",
    "\n",
    "```python\n",
    "ollama.embed(model='llama3.2', input='The sky is blue because of rayleigh scattering')\n",
    "```\n",
    "\n",
    "#### Embed (batch)\n",
    "\n",
    "```python\n",
    "ollama.embed(model='llama3.2', input=['The sky is blue because of rayleigh scattering', 'Grass is green because of chlorophyll'])\n",
    "```\n",
    "\n",
    "#### Ps\n",
    "\n",
    "```python\n",
    "ollama.ps()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d7e7a5-e62c-4280-82fd-ad0ffbc46696",
   "metadata": {},
   "source": [
    "### Errors\n",
    "\n",
    "Errors are raised if requests return an error status or if an error is detected while streaming.\n",
    "\n",
    "```python\n",
    "model = 'does-not-yet-exist'\n",
    "\n",
    "try:\n",
    "  ollama.chat(model)\n",
    "except ollama.ResponseError as e:\n",
    "  print('Error:', e.error)\n",
    "  if e.status_code == 404:\n",
    "    ollama.pull(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d976d5e-3db2-4ca9-ad19-06818f032f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe153a0-959d-4845-b001-7944c3ef9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.generate(model='deepseek-r1:7b', prompt='How to create a django project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69273a3d-a5bd-413e-82bf-85ea86c47c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I need to figure out how to create a Django project. I've heard that Django is a Python-based framework for building web applications, but honestly, I'm not too familiar with it yet. Let me think about where to start.\n",
       "\n",
       "First off, I know that Django requires some setup files and a backend server like PostgreSQL or MySQL. But wait, do I need to install both? Or can I have the server as part of Django's configuration?\n",
       "\n",
       "I remember seeing something about project configurations in Django. Maybe there are specific settings for the database. How does that work exactly? Should I run a command after creating the project to set it up?\n",
       "\n",
       "Also, I'm not sure if Django comes with built-in management commands or if those need to be installed separately. Oh right, the management tab in Django has those commands, so maybe they're part of the standard setup.\n",
       "\n",
       "Wait, do I need any third-party apps for a basic project? Like authentication or user management out of the box? Or is that something I add later?\n",
       "\n",
       "I think the first step is to create the project directory. How do I do that in the command line? Oh right, it's just `django-admin startproject myapp`. That should create the project and a migration file.\n",
       "\n",
       "After creating the project, I need to initialize it with Django's settings. So the next command would be `python manage.py migrate -- Interactive shell...` Hmm, but do I have to run that immediately after, or can I configure things later?\n",
       "\n",
       "Then, I'll probably want to set up the database configuration. Maybe using an .sqlite3 file? Or is that only for SQLite databases? Oh right, SQLite is a good option because it's built-in and easy to use.\n",
       "\n",
       "Wait, do I need to run any migrations after setting up the base configuration? Yes, the `migrate` command creates the initial database structure. So after creating myapp.db, which I get from Django's management commands, I should make sure that's set in my settings.py.\n",
       "\n",
       "Let me think about the steps:\n",
       "\n",
       "1. Install Django if I haven't already.\n",
       "2. Create a new project using startproject.\n",
       "3. Migrate to update the database schema.\n",
       "4. Configure the database settings, including connections for multiple databases if needed.\n",
       "5. Set up any third-party apps or add-ons later as required.\n",
       "\n",
       "I'm a bit confused about how to handle multiple databases. Do I need separate .sqlite3 files for each one? Or can I have them all in the same myapp.db?\n",
       "\n",
       "Also, what's the purpose of migrations exactly? Are they necessary every time I change the database schema, or are they just updates after an initial setup?\n",
       "\n",
       "I think I should run `python manage.py migrate` right after creating the project to apply the default migrations. But if I need a custom migration script later, how do I handle that without overwriting the defaults?\n",
       "\n",
       "Another thing: where is the settings.py file located? It's in the project directory under myapp, or somewhere else? Oh no, waitâ€”no, actually, Django looks for settings.py at the root of your app. So if I'm creating a project called 'myapp', then my app would be inside that project.\n",
       "\n",
       "Wait, maybe I got that wrong. When you create a project with `startproject`, it creates an 'myapp' directory under project, and settings are in project/settings.py by default?\n",
       "\n",
       "No, actually, no. Wait, the project structure is project/[app]/settings.py. So if my project is called 'myapp_project', then the apps would be inside that root. But when I run `startproject`, it creates a new 'project' directory with an 'app' subdirectory containing all my apps.\n",
       "\n",
       "Wait, maybe I'm mixing up things here. Let me think again: Django projects are created in a directory structure where your app is under project/[app]/.\n",
       "\n",
       "So if I do `django-admin startproject myapp_project`, it creates a project directory called myapp_project with an app named apps inside it. Then the settings file should be in myapp_project/settings.py by default, right?\n",
       "\n",
       "But maybe that's getting too detailed for now. I just need to know that after creating the project, running `migrate` will handle the initial setup.\n",
       "\n",
       "Also, if I'm using a custom database driver, like PostgreSQL or MySQL, I need to set that up in settings.py and configure Django to use it with the right configuration options.\n",
       "\n",
       "I think there are also some security considerations when setting up the database. Like making sure to run migrations on development environments but not on production? Or is that handled automatically?\n",
       "\n",
       "Another thing: using .env files for environment variables would be helpful, so I should make sure to configure those correctly in my settings.py or elsewhere.\n",
       "\n",
       "Hmm, this is getting a bit overwhelming. Maybe I should follow the official Django setup guide step by step to ensure I don't miss anything important.\n",
       "</think>\n",
       "\n",
       "To create a Django project and set it up properly, follow these organized steps:\n",
       "\n",
       "1. **Install Django**: If you haven't already, install Django using pip:\n",
       "   ```bash\n",
       "   pip install django\n",
       "   ```\n",
       "\n",
       "2. **Create the Project Directory**:\n",
       "   Start by creating a new Django project in your preferred location (e.g., `myapp_project`):\n",
       "   ```bash\n",
       "   django-admin startproject myapp_project\n",
       "   ```\n",
       "   This creates a `myapp_project` directory with an `__init__.py` file and an `apps` subdirectory.\n",
       "\n",
       "3. **Run Migration**:\n",
       "   Perform the initial database migrations to set up your project's default structure:\n",
       "   ```bash\n",
       "   python manage.py migrate --yes\n",
       "   ```\n",
       "\n",
       "4. **Configure Django Settings**:\n",
       "   Locate or create a `settings.py` file in your project root (inside `myapp_project`). Configure your development settings, including URLs and other configurations.\n",
       "\n",
       "5. **Database Configuration**:\n",
       "   Set up your database using a configuration file if needed. For SQLite:\n",
       "   ```bash\n",
       "   python manage.py makemigrations --yes\n",
       "   python manage.py migrate --yes\n",
       "   ```\n",
       "   Your apps must reference the database in `settings.py` (e.g., `DATABASES = {'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': 'myapp.db'}}`).\n",
       "\n",
       "6. **Run Management Commands**:\n",
       "   Use Django's management tab to run commands like `makemigrations`, `migrate`, and `db close` when needed.\n",
       "\n",
       "7. **Set Up Third-Party Apps** (if required):\n",
       "   Install additional apps using pip, then configure them in your project's `settings.py`.\n",
       "\n",
       "8. **Start the Server**:\n",
       "   Run the Django server to access your application via a web browser or terminal:\n",
       "   ```bash\n",
       "   python manage.py runserver\n",
       "   ```\n",
       "\n",
       "By following these steps, you'll have a properly initialized Django project with a configured database structure and setup ready for your web application development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf88d62-13fe-4d35-9f8d-22f31c22e1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
