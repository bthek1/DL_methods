{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32a72b4-daaf-43eb-a851-605e9b4f9a8b",
   "metadata": {},
   "source": [
    "# Ollama\n",
    "\n",
    "> Ollama is a lightweight, extensible framework designed for building and running large language models (LLMs) on local machines. It provides a command-line interface (CLI) that facilitates model management, customization, and interaction. Here's a comprehensive guide to using Ollama, including essential commands and examples.\n",
    "\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d25416-0ed7-4f85-bf3c-bdbc07a44dc0",
   "metadata": {},
   "source": [
    "## **1. Installation**\n",
    "\n",
    "- **For Linux:**\n",
    "\n",
    "  Open your terminal and execute:\n",
    "\n",
    "  ```bash\n",
    "  curl -fsSL https://ollama.com/install.sh | sh\n",
    "  ```\n",
    "\n",
    "  This command downloads and installs Ollama on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aea2e0-1da6-4bd6-8a3a-22af6a9d8138",
   "metadata": {},
   "source": [
    "## **2. System Requirements**\n",
    "\n",
    "- **Operating System:** macOS or Linux\n",
    "- **Memory (RAM):** Minimum 8GB; 16GB or more recommended\n",
    "- **Storage:** At least 10GB of free space\n",
    "- **Processor:** Modern CPU from the last 5 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fb26e-0997-41f9-8c81-2121ccd768c6",
   "metadata": {},
   "source": [
    "## **3. Basic CLI Commands**\n",
    "\n",
    "- **Start the Ollama Server:**\n",
    "\n",
    "  To run Ollama without the desktop application:\n",
    "\n",
    "  ```bash\n",
    "  ollama serve\n",
    "  ```\n",
    "\n",
    "- **Download a Model:**\n",
    "\n",
    "  To download a specific model:\n",
    "\n",
    "  ```bash\n",
    "  ollama pull <model-name>\n",
    "  ```\n",
    "\n",
    "  Replace `<model-name>` with the desired model's name, e.g., `llama3.2`.\n",
    "\n",
    "- **List Downloaded Models:**\n",
    "\n",
    "  To view all models available on your system:\n",
    "\n",
    "  ```bash\n",
    "  ollama list\n",
    "  ```\n",
    "\n",
    "- **Run a Model:**\n",
    "\n",
    "  To start a model and enter an interactive session:\n",
    "\n",
    "  ```bash\n",
    "  ollama run <model-name>\n",
    "  ```\n",
    "\n",
    "  For example:\n",
    "\n",
    "  ```bash\n",
    "  ollama run llama3.2\n",
    "  ```\n",
    "\n",
    "- **Stop a Running Model:**\n",
    "\n",
    "  To stop a specific model:\n",
    "\n",
    "  ```bash\n",
    "  ollama stop <model-name>\n",
    "  ```\n",
    "\n",
    "- **Remove a Model:**\n",
    "\n",
    "  To delete a model from your system:\n",
    "\n",
    "  ```bash\n",
    "  ollama rm <model-name>\n",
    "  ```\n",
    "\n",
    "- **Display Model Information:**\n",
    "\n",
    "  To view details about a specific model:\n",
    "\n",
    "  ```bash\n",
    "  ollama show <model-name>\n",
    "  ```\n",
    "\n",
    "- **List Running Models:**\n",
    "\n",
    "  To see which models are currently active:\n",
    "\n",
    "  ```bash\n",
    "  ollama ps\n",
    "  ```\n",
    "\n",
    "- **Access Help:**\n",
    "\n",
    "  For a list of available commands and their descriptions:\n",
    "\n",
    "  ```bash\n",
    "  ollama help\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8b786-4f0e-4d8e-a1cc-d749ce96b14b",
   "metadata": {},
   "source": [
    "## **4. Model Customization**\n",
    "\n",
    "Ollama allows users to customize models using a `Modelfile`. This file specifies the base model and any modifications, such as system prompts or parameters.\n",
    "\n",
    "- **Create a `Modelfile`:**\n",
    "\n",
    "  Create a file named `Modelfile` with the following content:\n",
    "\n",
    "  ```\n",
    "  FROM llama3.2\n",
    "\n",
    "  SYSTEM \"You are an AI assistant specializing in environmental science. Answer all questions with a focus on sustainability.\"\n",
    "\n",
    "  PARAMETER temperature 0.7\n",
    "  ```\n",
    "\n",
    "- **Build the Custom Model:**\n",
    "\n",
    "  Use the `ollama create` command to build the model:\n",
    "\n",
    "  ```bash\n",
    "  ollama create my_custom_model -f ./Modelfile\n",
    "  ```\n",
    "\n",
    "- **Run the Custom Model:**\n",
    "\n",
    "  Start the customized model:\n",
    "\n",
    "  ```bash\n",
    "  ollama run my_custom_model\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fbfea8-0142-49f5-b09a-2ec3dde0f486",
   "metadata": {},
   "source": [
    "## **5. Using Ollama with Files**\n",
    "\n",
    "- **Summarize Text from a File:**\n",
    "\n",
    "  To summarize the content of `input.txt`:\n",
    "\n",
    "  ```bash\n",
    "  ollama run llama3.2 \"Summarize the content of this file.\" < input.txt\n",
    "  ```\n",
    "\n",
    "- **Save Model Responses to a File:**\n",
    "\n",
    "  To save the model's response to `output.txt`:\n",
    "\n",
    "  ```bash\n",
    "  ollama run llama3.2 \"Explain the concept of quantum computing.\" > output.txt\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb3949-a71a-4a6c-bd41-f60665a55272",
   "metadata": {},
   "source": [
    "## **6. Common Use Cases**\n",
    "\n",
    "- **Text Generation:**\n",
    "\n",
    "  - *Content Creation:*\n",
    "\n",
    "    Generate an article on a specific topic:\n",
    "\n",
    "    ```bash\n",
    "    ollama run llama3.2 \"Write a short article on the benefits of renewable energy.\" > article.txt\n",
    "    ```\n",
    "\n",
    "  - *Question Answering:*\n",
    "\n",
    "    Answer specific queries:\n",
    "\n",
    "    ```bash\n",
    "    ollama run llama3.2 \"What are the latest advancements in artificial intelligence?\"\n",
    "    ```\n",
    "\n",
    "- **Data Analysis:**\n",
    "\n",
    "  - *Sentiment Analysis:*\n",
    "\n",
    "    Analyze the sentiment of a given text:\n",
    "\n",
    "    ```bash\n",
    "    ollama run llama3.2 \"Determine the sentiment of this review: 'The product exceeded my expectations.'\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea66d3-aa27-44f6-9870-e1556e16ba79",
   "metadata": {},
   "source": [
    "## **7. Python Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73633df6-5396-4b58-b190-289fe2a22a8d",
   "metadata": {},
   "source": [
    "### Ollama Python Library\n",
    "\n",
    "The Ollama Python library provides the easiest way to integrate Python 3.8+ projects with [Ollama](https://github.com/ollama/ollama)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2164a91-b651-4937-be63-db837e2ef2a4",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "- [Ollama](https://ollama.com/download) should be installed and running\n",
    "- Pull a model to use with the library: `ollama pull <model>` e.g. `ollama pull llama3.2`\n",
    "  - See [Ollama.com](https://ollama.com/search) for more information on the models available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621fda2-7304-4da2-8b09-1047d8a062ad",
   "metadata": {},
   "source": [
    "### Install\n",
    "\n",
    "```sh\n",
    "pip install ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e4941-305e-405b-aabc-db9969f7f439",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "```python\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)\n",
    "```\n",
    "\n",
    "See [_types.py](ollama/_types.py) for more information on the response types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de768f-e0ac-454e-a9e7-884b84fd7cc0",
   "metadata": {},
   "source": [
    "### Streaming responses\n",
    "\n",
    "Response streaming can be enabled by setting `stream=True`.\n",
    "\n",
    "```python\n",
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model='llama3.2',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffbac4-7d00-4154-9efd-143488c852c6",
   "metadata": {},
   "source": [
    "### Custom client\n",
    "A custom client can be created by instantiating `Client` or `AsyncClient` from `ollama`.\n",
    "\n",
    "All extra keyword arguments are passed into the [`httpx.Client`](https://www.python-httpx.org/api/#client).\n",
    "\n",
    "```python\n",
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")\n",
    "response = client.chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c0a0c-0266-444e-befa-e1254554d4f2",
   "metadata": {},
   "source": [
    "### Async client\n",
    "\n",
    "The `AsyncClient` class is used to make asynchronous requests. It can be configured with the same fields as the `Client` class.\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "\n",
    "async def chat():\n",
    "  message = {'role': 'user', 'content': 'Why is the sky blue?'}\n",
    "  response = await AsyncClient().chat(model='llama3.2', messages=[message])\n",
    "\n",
    "asyncio.run(chat())\n",
    "```\n",
    "\n",
    "Setting `stream=True` modifies functions to return a Python asynchronous generator:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "\n",
    "async def chat():\n",
    "  message = {'role': 'user', 'content': 'Why is the sky blue?'}\n",
    "  async for part in await AsyncClient().chat(model='llama3.2', messages=[message], stream=True):\n",
    "    print(part['message']['content'], end='', flush=True)\n",
    "\n",
    "asyncio.run(chat())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae65c53-4924-49e1-a05f-5ebce1cb821b",
   "metadata": {},
   "source": [
    "### API\n",
    "\n",
    "The Ollama Python library's API is designed around the [Ollama REST API](https://github.com/ollama/ollama/blob/main/docs/api.md)\n",
    "\n",
    "#### Chat\n",
    "\n",
    "```python\n",
    "ollama.chat(model='llama3.2', messages=[{'role': 'user', 'content': 'Why is the sky blue?'}])\n",
    "```\n",
    "\n",
    "#### Generate\n",
    "\n",
    "```python\n",
    "ollama.generate(model='llama3.2', prompt='Why is the sky blue?')\n",
    "```\n",
    "\n",
    "#### List\n",
    "\n",
    "```python\n",
    "ollama.list()\n",
    "```\n",
    "\n",
    "#### Show\n",
    "\n",
    "```python\n",
    "ollama.show('llama3.2')\n",
    "```\n",
    "\n",
    "#### Create\n",
    "\n",
    "```python\n",
    "ollama.create(model='example', from_='llama3.2', system=\"You are Mario from Super Mario Bros.\")\n",
    "```\n",
    "\n",
    "#### Copy\n",
    "\n",
    "```python\n",
    "ollama.copy('llama3.2', 'user/llama3.2')\n",
    "```\n",
    "\n",
    "#### Delete\n",
    "\n",
    "```python\n",
    "ollama.delete('llama3.2')\n",
    "```\n",
    "\n",
    "#### Pull\n",
    "\n",
    "```python\n",
    "ollama.pull('llama3.2')\n",
    "```\n",
    "\n",
    "#### Push\n",
    "\n",
    "```python\n",
    "ollama.push('user/llama3.2')\n",
    "```\n",
    "\n",
    "#### Embed\n",
    "\n",
    "```python\n",
    "ollama.embed(model='llama3.2', input='The sky is blue because of rayleigh scattering')\n",
    "```\n",
    "\n",
    "#### Embed (batch)\n",
    "\n",
    "```python\n",
    "ollama.embed(model='llama3.2', input=['The sky is blue because of rayleigh scattering', 'Grass is green because of chlorophyll'])\n",
    "```\n",
    "\n",
    "#### Ps\n",
    "\n",
    "```python\n",
    "ollama.ps()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d7e7a5-e62c-4280-82fd-ad0ffbc46696",
   "metadata": {},
   "source": [
    "### Errors\n",
    "\n",
    "Errors are raised if requests return an error status or if an error is detected while streaming.\n",
    "\n",
    "```python\n",
    "model = 'does-not-yet-exist'\n",
    "\n",
    "try:\n",
    "  ollama.chat(model)\n",
    "except ollama.ResponseError as e:\n",
    "  print('Error:', e.error)\n",
    "  if e.status_code == 404:\n",
    "    ollama.pull(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d976d5e-3db2-4ca9-ad19-06818f032f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe153a0-959d-4845-b001-7944c3ef9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.generate(model='deepseek-r1:7b', prompt='write a haiku about time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69273a3d-a5bd-413e-82bf-85ea86c47c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, so I need to write a haiku about time. First off, what's a haiku? It's a traditional Japanese poem with three lines. The structure is usually 5 syllables in the first line, 7 in the second, and 5 again in the third. So it's got that 5-7-5 pattern.\n",
       "\n",
       "Okay, time-related themes can be pretty broad—ages, seasons passing, moments slipping away, etc. I want to capture something meaningful or introspective because haikus often evoke emotions or deep thoughts.\n",
       "\n",
       "Maybe I can focus on the passage of time. Like how time moves on without us noticing. Or perhaps something more personal, like aging. But maybe keeping it a bit more universal would be better for a haiku about time itself.\n",
       "\n",
       "Let me think about imagery associated with time. Clocks, watches, sun setting, seasons changing... Hmm, or maybe something more abstract like the ticking of a clock as an metaphor for life's flow.\n",
       "\n",
       "Wait, another angle: the fleeting nature of time, how it takes away memories and opportunities. That could add some poignancy to the haiku.\n",
       "\n",
       "So putting that together: first line about time moving on, second line showing something being taken by time, third line reflecting on its impact or wish for more time.\n",
       "\n",
       "Let me try drafting some lines.\n",
       "\n",
       "First line: \"Time's ticks tick on,\" – that gives a rhythmic feel and shows progression. But maybe make it more poetic: \"The clock ever moves.\"\n",
       "\n",
       "Second line: Something about what's lost to time. Maybe the things we hold dear now, like a child's laughter or a pet's presence. Or perhaps natural elements. \"A child's laughter fades.\"\n",
       "\n",
       "Third line: Reflecting on time's impact. \"Time's touch brings loss.\"\n",
       "\n",
       "Wait, that's three lines but not quite hitting the 5-7-5 syllable structure. Let me check.\n",
       "\n",
       "\"The clock ever moves.\" – That's 5 syllables.\n",
       "\"A child's laughter fades.\" – That's 8, which is too long for the second line. Hmm.\n",
       "\n",
       "Maybe adjust the second line to be more concise. \"A fleeting memory fades\" – that's longer but still not fitting. Alternatively, \"A moment slips away,\" which is 7 syllables: 5-7-?\n",
       "\n",
       "Third line needs to fit back into 5. Maybe \"Time takes what's near.\"\n",
       "\n",
       "Putting it together:\n",
       "\n",
       "The clock ever moves.\n",
       "A moment slips away.\n",
       "Time takes what's near.\n",
       "\n",
       "But that might not flow well. Let me try another approach, focusing more on the passage of time and its impact.\n",
       "\n",
       "First line: \"Time passes without end,\" – 5 syllables.\n",
       "Second line: \"Mornings shift to sunsets,\" – 7 syllables.\n",
       "Third line: \"Yet moments slip through.\"\n",
       "\n",
       "But maybe that's too straightforward. Maybe add a bit more depth or metaphor.\n",
       "\n",
       "Alternatively, using imagery like shadows for time moving:\n",
       "\n",
       "\"A shadow falls each day,\" – 5.\n",
       "\"The hours grow long and slow,\" – 7.\n",
       "\"Beware the time you waste.\" – 6 syllables, close but not quite.\n",
       "\n",
       "Hmm, maybe tweak it again. \"A shadow tugs at night\" (5), \"Sunlight fades as days pass\" (7), \"Time's hand is ever cold.\" (6). Still a bit off.\n",
       "\n",
       "Perhaps another angle: focusing on aging or growing older:\n",
       "\n",
       "\"Eyes see, hearts grow old,\" – 5.\n",
       "\"The sand in time's hourglass flows,\" – 8 again. Not good.\n",
       "\n",
       "Alternatively, \"The leaves fall silent,\" – 6 syllables. Hmm.\n",
       "\n",
       "Wait, maybe think about the inner experience of time—how it affects us as we age:\n",
       "\n",
       "\"Time whispers through our ears,\" – 7 syllables.\n",
       "\"Beneath our feet, shadows stretch,\" – 8.\n",
       "\"Young once, now gray and wise.\" – 7. Still not matching.\n",
       "\n",
       "I might need to adjust my approach. Maybe start with a metaphor for time, like something breaking or fading:\n",
       "\n",
       "\"The ink runs dry on yesterday's thought\" – 10 syllables. Too long.\n",
       "\n",
       "Or \"A river flows forever,\" but needs context about what's being carried by the river—perhaps memories or things lost.\n",
       "\n",
       "\"A river carries time away,\" – 7.\n",
       "\"But in its current, old notes remain.\" – 8.\n",
       "\n",
       "Not matching either.\n",
       "\n",
       "Alternatively, think of time as a thief:\n",
       "\n",
       "\"Thief of moments, ever present.\" – But syllables? Thief:3, of:1, etc. Maybe \"Theft of moments speeds by.\"\n",
       "\n",
       "Wait, maybe I'm overcomplicating it. Let's go back to the original structure and try to fit something meaningful.\n",
       "\n",
       "First line: \"Time moves on\" (5)\n",
       "Second line: \"Echoes fade away\" (7)\n",
       "Third line: \"Weep for what's past\" (6) – close but not 5.\n",
       "\n",
       "Or adjust third line to \"Weep for time's way.\"\n",
       "\n",
       "Wait, perhaps:\n",
       "\n",
       "1. Time ever flows,\n",
       "2. Moments fade into the past,\n",
       "3. A reminder of fleeting days.\n",
       "\n",
       "That gives 5-7-5 syllables and reflects on the passage of time with a somber tone.\n",
       "\n",
       "Yes, that might work. Each line captures part of the essence—time moving, moments passing, leaving behind memories.\n",
       "</think>\n",
       "\n",
       "Time ever flows,  \n",
       "Moments fade into the past,  \n",
       "A reminder of fleeting days."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response['response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf88d62-13fe-4d35-9f8d-22f31c22e1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
