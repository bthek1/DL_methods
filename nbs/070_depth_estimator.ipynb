{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49119fe-f5f8-4753-8b97-a4b1dfc34a7c",
   "metadata": {},
   "source": [
    "# Depth estimator\n",
    "\n",
    "> Depth estimator\n",
    "\n",
    "\n",
    "- skip_showdoc: true\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990be10e-54da-44e3-a742-8d4b9675e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, utils\n",
    "import urllib.request\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8472f1-c8e6-4322-b053-6b8fc580da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter()\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76eb3ad-8819-4f62-82cd-d5c002dda43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838a4fa-105e-403f-a2b6-9b171a64be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
    "model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc03de7-9b6a-4692-afc5-66ebbab0eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172ca58-687c-4c95-a399-956dff647ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419ba82-5f5b-4f06-89d1-41a03e69c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transforms.dpt_transform\n",
    "else:\n",
    "    transform = midas_transforms.small_transform\n",
    "\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcf22e-b18c-473d-bb2c-30b21a919c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(filename)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a09e46-0025-4765-ae02-ad242209a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = transform(img).to(device)\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502dd41-0beb-4cf8-8341-a6726d8c6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch.shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192b5ac-78b0-49df-8767-69d5b5edd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch.squeeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0b37c-7efb-4dc0-859f-0da158e9dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fabcdd-746d-45dc-9f8f-c3237b36389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch1 = input_batch.to('cpu')\n",
    "input_batch1 = input_batch1.squeeze()\n",
    "input_batch1 = input_batch1.numpy().transpose(1, 2, 0)\n",
    "input_batch1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d8b61-00b8-4aed-ba49-bc0af9db4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch2 = transform(input_batch1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98e85c-9248-4306-9d2e-cce75dcba150",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = midas(input_batch)\n",
    "\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        prediction.unsqueeze(1),\n",
    "        size=img.shape[:2],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    ).squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b661e0-18fd-4c5a-97f5-f092bffba37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming img_tensor is your image tensor\n",
    "img_range = (torch.max(prediction) - torch.min(prediction))\n",
    "\n",
    "# Rescale the tensor to the range [0, 1]\n",
    "prediction = ((prediction - torch.min(prediction)) / img_range) * 255\n",
    "\n",
    "# Convert the tensor to integers (rounding) and change data type to uint8\n",
    "prediction = prediction.round().to(torch.uint8)\n",
    "\n",
    "output = prediction.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53848714-3511-489f-bffc-46c6ea5c9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c3cf5-b460-40a3-9357-6bd167ea20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fea4e7-48ff-4884-9634-9c6869e84f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eec071-c885-4ca0-a2a0-7e819c69905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a87d2-43d3-4bc5-aa98-a843241e8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "writer.add_image('mnist_images', img,\n",
    "                 global_step=0,\n",
    "                 dataformats='HWC')\n",
    "writer.add_image('output', output,\n",
    "                 global_step=0,\n",
    "                 dataformats='HW')\n",
    "writer.flush()\n",
    "#sys.exit()\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ce40f-aafd-4bbc-a383-20ce99ebea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd6c5a-d45f-4e01-b213-acdb7f395484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
